[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "다변량통계학-2025년 2학기",
    "section": "",
    "text": "Preface\n이 책은 2025년 다변량통계학에 대한 온라인 교재입니다.\n\n\n\n\n\n\n표기법\n\n\n\n이 책에서 사용된 기호, 표기법, 프로그램의 규칙과 쓰임은 다음과 같습니다.\n\n스칼라(scalar)와 일변량 확률변수는 일반적으로 보통 글씨체의 소문자로 표기한다. 특별한 이유가 있는 경우 대문자로 표시할 것이다.\n벡터, 행렬, 다변량 확률벡터는 굵은 글씨체로 표기한다.\n통계 프로그램은 R을 이용하였다. 각 예제에 사용된 R 프로그램은 코드 상자를 열면 나타난다.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "qmd/multivar-dist.html",
    "href": "qmd/multivar-dist.html",
    "title": "1  확률벡터와 다변량 정규분포",
    "section": "",
    "text": "1.1 예제- 국민체력100\n다변량 자료(multivariate data)는 두 개 이상의 변수를 측정한 자료를 말합니다. 예를 들어, 학생들의 키와 몸무게, 시험 점수와 공부 시간, 나이와 소득 등이 다변량 자료에 해당합니다. 다변량 자료는 변수들 간의 관계를 분석하고 이해하는 데 중요한 역할을 합니다. 다변량 자료를 효과적으로 표현하고 분석하기 위해 다양한 그래프와 통계 기법이 사용됩니다. 이 장에서는 다변량 자료의 표현 방법과 분포를 이해하는 데 필요한 기본 개념과 도구들을 소개합니다.\n국민체력100은 국민의 체력증진과 건강증진을 위해 개발된 종합적인 체력측정 프로그램이다. 이 프로그램은 다양한 연령대와 성별에 맞춘 체력측정 항목을 포함하고 있으며, 이를 통해 개인의 체력 상태를 평가하고 개선할 수 있는 기회를 제공한다.\n이번 장에서는 청소년(13-18세) 남여 3000명에 대하여 2024년에 국민체력100 사업에서 측정한 자료를 예제로 사용하여 다변량 자료를 표현하는 방법들과 분포를 배울것이다.\n먼저 측정항목에 대한 설명에 대한 자료를 보자.\nload(here(\"data\", \"physical100.RData\"))\nls()\n\n[1] \"physical100_df\"      \"physical100_df_info\"\n먼저 데이터프레임 selected_var_df 에는 측정한 항목의 영문 변수이름(varname_eng), 종목의 설명(varname_kor), 측정분야(category_kor) 그리고 측정단위(unit) 가 다음과 같이 저장되어 있다.\nvarname_engvarname_korcategory_korunitheight신장신체구성cmweight체중신체구성kgbody_fat_pct체지방율신체구성grip_left악력_좌근력kggrip_right악력_우근력kgsit_forward앉아윗몸앞으로굽히기유연성cmillinois일리노이민첩성초hang_time청소년체공시간순발력초twall_timeTWALL_시간협응력초twall_errorsTWALL_실수협응력회twall_scoreTWALL_결과값협응력초bmiBMI신체구성rel_grip상대악력근력%abs_grip절대악력근력kg\n다음으로 청소년 3000명의 측정 자료의 일부는 다음과 같다.\nsexageheightweightbody_fat_pctgrip_leftsit_forward남성15166.568.026.331.922.1여성13166.445.522.020.010.2남성13163.244.711.722.0-2.0여성14156.944.726.917.3-5.0남성17175.778.116.752.218.5여성16167.274.537.125.912.0여성16162.057.337.121.6-4.5여성17169.175.039.821.60.1여성15160.956.833.125.1-8.0남성13162.857.618.039.628.0",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>확률벡터와 다변량 정규분포</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-dist.html#확률벡터와-기본-성질",
    "href": "qmd/multivar-dist.html#확률벡터와-기본-성질",
    "title": "1  확률벡터와 다변량 정규분포",
    "section": "1.2 확률벡터와 기본 성질",
    "text": "1.2 확률벡터와 기본 성질\n\n1.2.1 일변량 확률변수\n일변량 확률변수(random variable) \\(X\\)가 확률밀도함수 \\(f(x)\\)를 가지는 분포를 따를때 기대값과 분산은 다음과 같이 정의된다.\n\\[\n\\begin{aligned}\nE(X) & = \\int x f(x)  dx = \\mu\\\\\nV(X) & = E[ X-E(X)]^2=\\int (x-\\mu)^2 f(x) dx =\\sigma^2\n\\end{aligned}\n\\]\n새로운 확률변수 \\(Y\\)가 확률변수 \\(X\\)의 다음과 같은 선형변환으로 표시된다면 (\\(a\\)와 \\(b\\)는 실수)\n\\[ Y = aX+b \\]\n일변량 확률변수 \\(X\\)의 기대값(평균)과 분산은 다음과 같이 계산된다.\n\\[\n\\begin{aligned}\nE(Y) & = E(aX+b) \\\\\n& = \\int (ax+b) f(x) dx \\\\\n& = a \\int x f(x) dx + b \\\\\n& = a E(X) + b\\\\\n& = a \\mu + b\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\nV(Y) & = Var(aX+b) \\\\\n& = E[aX+b -E(aX+b)]^2 \\\\\n& = E[a(X-\\mu)]^2 \\\\\n& = a^2 E(X-\\mu)^2\\\\\n& = a^2 \\sigma^2\n\\end{aligned}\n\\]\n\n\n1.2.2 다변량 확률벡터\n이제 하나의 학률변수가 아는 2개 이상의 확률변수들을 모아놓은 확률벡터(random vector)를 생각해 보자. 다음과 같이 벡터로 표현된 확률벡터 \\(\\pmb X\\)가 \\(p\\) 차원의 다변량 분포(multivariate distribution)를 따른다고 하고 결합확률밀도함수 \\(f(\\pmb x) =f(x_1,x_2,\\dots,x_p)\\)를 를 가진다고 하자.\n\\[\n\\pmb X =\n  \\begin{bmatrix}\nX_1 \\\\\nX_2 \\\\\nX_3 \\\\\n..  \\\\\nX_p\n\\end{bmatrix}\n\\]\n다변량 확률벡터의 평균 벡터(mean vector)는 다음과 같이 주어진다. 확률벡터의 평균 벡터는 구성하는 각 확률변수의 평균으로 주어진다.\n\\[\n\\pmb E(\\pmb X) =\n  \\begin{bmatrix}\nE(X_1) \\\\\nE(X_2) \\\\\nE(X_3) \\\\\n..  \\\\\nE(X_p)\n\\end{bmatrix}\n=\n  \\begin{bmatrix}\n\\mu_1 \\\\\n\\mu_2 \\\\\n..  \\\\\n\\mu_p\n\\end{bmatrix}\n=\\pmb \\mu\n\\]\n다음으로 공분산(covariance)과 상관계수(correlation coefficient)에 대해서 알아보자. 우리는 여러 개의 확률 변수의 관계를 분석하는 분석을 하려고 하는데, 이 경우 가장 많이 사용되는 통계량이 두 개의 변수들의 선형적 관계를 나타내는 상관계수이다. 두 확률변수 \\(X_k\\) 와 \\(X_l\\) 의 상관계수 \\(\\rho_{jk}\\) 는 다음과 같이 정의된다.\n\\[\n\\rho_{jk} = \\frac{Cov(X_j, X_k)}{ \\sqrt{V(X_j) V(X_k)}} = \\frac{\\sigma_{jk}}{\\sqrt{\\sigma_{jj}\n  \\sigma_{kk}}}, \\quad j,k=1,2,\\dots,p\n\\]\n위의 상관계수의 공식에서 \\(\\sigma_{jj} \\equiv \\sigma^2_j\\) 와 \\(\\sigma_{kk} = \\sigma^2_k\\) 는 각각 확률변수 \\(X_i\\) 와 \\(X_j\\) 의 분산이며, 공분산은 다음과 같이 정의된다.\n\\[\n\\begin{aligned}\nCov(X_j, X_k) & = E [(X_j - E(X_j))(X_k - E(X_k))] \\\\\n& = E(X_j  X_k) - E(X_j)E(X_k)\n\\end{aligned}\n\\]\n위의 식을 보면 각각의 확률 변수가 평균에서 차이가 나는 두 개의 편차, 즉 \\(X_j - E(X_j)\\), \\(X_k - E(X_k)\\) 의 곱에 대한 기대값으로 두 확률 변수가 평균에서 얼마나 같은 방향 또는 반대 방향으로 함께 움직이는 경향이 있는지 그 정도를 수치화한 값이다. 두 확률변수의 공분산의 값이 양의 값으로 커지면 두 확률 변수의 변화가 같은 방향으로 나타난다는 의미이며, 반대로 음의 값으로 커지면 두 확률 변수의 변화가 반대 방향으로 나타난다는 의미이다.\n참고로 공분산은 단위가 확률 변수의 단위에 영향을 받기 떄문에 크기 자체만으로 비교가 직관적이지 않다는 단점이 있다. 반면에 상관 계수는 공분산을 각 확률 변수의 표분편차로 나누어 얻은 값이므로 단위에 영향을 받지 않아서 상대적인 비교가 가능하다.\n상관계수는 -1 과 1 사이의 값을 가지며 1에 가까울수록 두 개의 변수가 같은 방향으로 움직이는 확률적 경향이 강해지며 반대로 -1 에 가까워질수록 반대의 방향을 움직이는 경향이 강해진다.\n여기서 중요한 점은 상관계수(또는 공분산)은 두 확률 변수의 선형적 관계(linear relationship)을 나타내는 통계량으로 비선형적 관계를 파악하는데는 한계가 있을 수 있다.\n이제 확률 벡터의 모든 변수에 대한 분산과 공분산을 다음과 같은 공분산 행렬로 나타낼 수 있다.\n\\[\n\\begin{aligned}\nV(\\pmb X) & = Cov(\\pmb X) = E (\\pmb X-\\pmb \\mu) (\\pmb X-\\pmb \\mu)^t \\\\\n& = E(\\pmb X \\pmb X^t)-\\pmb \\mu \\pmb  \\mu^t\\\\\n& =\n  \\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\dots & \\sigma_{1p} \\\\\n\\sigma_{12} & \\sigma_{22} & \\dots & \\sigma_{2p} \\\\\n& \\dots & \\dots & \\\\\n\\sigma_{1p} & \\sigma_{2p} & \\dots & \\sigma_{pp} \\\\\n\\end{bmatrix} \\\\\n& = \\pmb \\Sigma\n\\end{aligned}\n\\]\n여기서 \\(\\sigma_{jj}=V(X_j)\\), \\(\\sigma_{jk} = Cov(X_j, X_k)=Cov(X_k, X_j)\\) 이다. 따라서 공분산 행렬 \\(\\pmb \\Sigma\\)는 대칭행렬(symmetric matrix)이다.\n더 나아가 확률 벡터의 모든 변수에 대한 상관계수을 다음과 같은 상관계수 행렬(correlation matrix) \\(\\pmb R\\) 로 나타낼 수 있다.\n\\[\n\\begin{aligned}\ncor(\\pmb X) & =\n  \\begin{bmatrix}\n1 & \\rho_{12} & \\dots & \\rho_{1p} \\\\\n\\rho_{12} & 1 & \\dots & \\rho_{2p} \\\\\n& \\dots & \\dots & \\\\\n\\rho_{1p} & \\rho_{2p} & \\dots & 1 \\\\\n\\end{bmatrix} \\\\\n& = \\pmb R\n\\end{aligned}\n\\]\n위의 상관계수 행렬에서 대각원소는 모두 1 임이 유의하자.\n새로운 확률벡터 \\(\\pmb Y\\)가 확률벡터 \\(\\pmb X\\) 의 선형변환라고 하자.\n\\[ \\pmb Y = \\pmb A  \\pmb X + \\pmb b \\]\n단 여기서 \\(\\pmb A\\) 는 \\(p \\times p\\) 실수 행렬이고 \\(\\pmb b\\) 는 \\(p \\times 1\\) 실수 벡터이다.\n확률벡터 \\(\\pmb Y\\)의 기대값(평균벡터)과 공분산은 다음과 같이 계산된다.\n\\[\n\\begin{aligned}\nE(\\pmb Y ) &= E(\\pmb A \\pmb X+ \\pmb b) \\\\\n&= \\pmb A E(\\pmb X)+ \\pmb b \\\\\n&= \\pmb A \\pmb \\mu+ \\pmb b \\\\\nV(\\pmb Y) &= Var(\\pmb A \\pmb X+ \\pmb b) \\\\\n&= E[\\pmb A \\pmb X+ \\pmb b -E(\\pmb A \\pmb X+ \\pmb b)] [\\pmb A \\pmb X+ \\pmb b -E(\\pmb A \\pmb X+ \\pmb b)]^t \\\\\n&= E[\\pmb A \\pmb X -  \\pmb A \\pmb \\mu] [\\pmb A \\pmb X -  \\pmb A \\pmb \\mu]^t \\\\\n&= E[\\pmb A (\\pmb X - \\pmb \\mu)] [\\pmb A (\\pmb X - \\pmb \\mu)]^t \\\\\n&=  E [\\pmb A(\\pmb X - \\pmb \\mu) (\\pmb X - \\pmb \\mu)^t  \\pmb A^t ] \\\\\n&= \\pmb A E [(\\pmb X - \\pmb \\mu) (\\pmb X - \\pmb \\mu)^t] \\pmb A^t \\\\\n&= \\pmb A \\pmb \\Sigma \\pmb A^t\n\\end{aligned}\n\\]\n\n\n1.2.3 표본 통계량\n이제 확률 표본(sample)을 이용하여 평균벡터, 공분산, 상관계수를 추정하는 간단한 방법에 대해서 알아보자.\n확률 벡터 \\(\\pmb X\\) 가 평균이 \\(\\pmb \\mu\\) 이고 공분산이 \\(\\pmb \\Sigma\\) 인 다변량 분포 \\(F\\) 를 따른다고 가정하자. 만약 확률 표본 \\(\\pmb X_1, \\pmb X_2, \\dots, \\pmb X_n\\) 이 독립적으로 다변량 분포 \\(F\\) 에서 임의로 추출되었다면\n\\[\n\\pmb X_i =\n\\begin{bmatrix}\nX_{i1} \\\\\nX_{i2} \\\\\nX_{i3} \\\\\n..  \\\\\nX_{ip}\n\\end{bmatrix}\n\\quad i=1,2,\\dots,n\n\\]\n다음과 같이 표본 통계량을 이용하여 평균벡터, 공분산, 상관계수를 추정할 수 있다.\n먼저 다음과 같은 표본평균 벡터 \\(\\bar {\\pmb X}\\) 는 평균벡터 \\(\\pmb \\mu\\) 의 불편추정량(unbiased estimator)이다.\n\\[\n\\bar {\\pmb X} =\n  \\begin{bmatrix}\n\\bar X_1  \\\\\n\\bar X_2  \\\\\n\\bar X_3  \\\\\n..  \\\\\n\\bar X_p  \\\\\n\\end{bmatrix}\n=\n  \\begin{bmatrix}\n\\sum_{i=1}^n X_{i1} / n  \\\\\n\\sum_{i=1}^n X_{i2} / n \\\\\n\\sum_{i=1}^n X_{i3} / n \\\\\n..  \\\\\n\\sum_{i=1}^n X_{ip} / n\n\\end{bmatrix}\n=\n\\hat {\\pmb \\mu}\n\\]\n여기서 \\(X_{ij}\\) 는 \\(i\\)번째 표본벡터 \\(\\pmb X_i =(X_{i1} X_{i2} \\dots X_{ip})^t\\)의 \\(j\\)번째 확률변수이다.\n또한 아래에 주어진 표본 공분산 행렬 \\(\\pmb S\\) 은 공분산 행렬 \\(\\pmb \\Sigma\\) 의 추정량이다.\n\\[\n\\pmb S\n=\n  \\begin{bmatrix}\ns_{11} & s_{12} & \\dots & s_{1p} \\\\\ns_{12} & s_{22} & \\dots & s_{2p} \\\\\n& \\dots & \\dots & \\\\\ns_{1p} & s_{2p} & \\dots & s_{pp} \\\\\n\\end{bmatrix}\n=\n\\hat {\\pmb \\Sigma}\n\\] 위에서 \\(s_{jj} \\equiv s^2_j\\) 는 확률변수 \\(X_j\\) 의 표본 분산이며 \\(s_{jk}\\) 는 \\(X_j\\) 와 \\(X_k\\) 의 표본 공분산이며 다음과 같이 계산된다.\n\\[\ns_{jj} = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar X_j)^2, \\quad\ns_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n (X_{ij} - \\bar X_j)(X_{ik} - \\bar X_k), \\quad j,k=1,2,\\dots,p\n\\]\n마지막으로 아래에 주어진 표본 상관계수 행렬 \\(\\pmb R\\) 은 상관계수 행렬 \\(\\pmb R\\) 의 추정량이다.\n\\[\n\\hat {\\pmb R} =\n  \\begin{bmatrix}\n1 & r_{12} & \\dots & r_{1p} \\\\\nr_{12} & 1 & \\dots & r_{2p} \\\\\n& \\dots & \\dots & \\\\\nr_{1p} & r_{2p} & \\dots & 1 \\\\\n\\end{bmatrix}\n\\]\n여기서 \\(r_{jk}\\) 는 확률변수 \\(X_j\\) 와 \\(X_k\\) 의 표본 상관계수이며 다음과 같이 계산된다.\n\\[\nr_{jk} = \\frac{s_{jk}}{\\sqrt{s_{jj} s_{kk}}}, \\quad j,k=1,2,\\dots,p\n\\]\n\n\n1.2.4 예제-국민체력100\n이제 위에서 샇펴본 국민체력100 자료에서 청소년 남자 자료를 이용하여 평균벡터, 공분산 행렬, 상관계수 행렬의 표본 통계량을 계산해 보자.\n먼저 표본 평균 벡터를 계산해 보자. 주어진 변수가 많으니 키(height), 몸무게(weight), 체지방률(body_fat_pct), 악력(grip_left), 앉아윗몸앞으로굽히기(sit_forward), 청소년체공시간(hang_time) 6개 변수만 선택하여 계산해 보자.\n\n# 국민체력100 자료에서 남자만 선택하여 데이터프레임 df 생성\ndf &lt;- physical100_df %&gt;% \n  filter(sex == \"남성\") %&gt;%\n  select(height, weight, body_fat_pct, grip_left, sit_forward,hang_time)\n\n#  패키지 dplyr의 summarise()와 across() 함수를 사용하여 각 열의 평균 계산\nsample_mean_vector &lt;- df %&gt;%\n  summarise(across(everything(), \\(x) mean(x, na.rm = TRUE))) %&gt;%\n  unlist()\n\nsample_mean_vector\n\n      height       weight body_fat_pct    grip_left  sit_forward    hang_time \n 172.0451492   69.7115470   20.9993923   36.0728729    7.8976630    0.5593964 \n\n\n다음으로 표본 공분산 행렬을 계산해 보자.\n\ncor(df)\n\n                    height      weight body_fat_pct   grip_left   sit_forward\nheight        1.0000000000  0.50994161  -0.03019400  0.45225668  0.0008938941\nweight        0.5099416134  1.00000000   0.69156075  0.46152254  0.0111910927\nbody_fat_pct -0.0301940037  0.69156075   1.00000000 -0.01208826 -0.1434596849\ngrip_left     0.4522566754  0.46152254  -0.01208826  1.00000000  0.2605654264\nsit_forward   0.0008938941  0.01119109  -0.14345968  0.26056543  1.0000000000\nhang_time     0.1884978140 -0.14265212  -0.48446817  0.34559521  0.2889235491\n              hang_time\nheight        0.1884978\nweight       -0.1426521\nbody_fat_pct -0.4844682\ngrip_left     0.3455952\nsit_forward   0.2889235\nhang_time     1.0000000\n\n\n마지막으로 표본 상관계수 행렬을 계산해 보자.\n\ncor(df)\n\n                    height      weight body_fat_pct   grip_left   sit_forward\nheight        1.0000000000  0.50994161  -0.03019400  0.45225668  0.0008938941\nweight        0.5099416134  1.00000000   0.69156075  0.46152254  0.0111910927\nbody_fat_pct -0.0301940037  0.69156075   1.00000000 -0.01208826 -0.1434596849\ngrip_left     0.4522566754  0.46152254  -0.01208826  1.00000000  0.2605654264\nsit_forward   0.0008938941  0.01119109  -0.14345968  0.26056543  1.0000000000\nhang_time     0.1884978140 -0.14265212  -0.48446817  0.34559521  0.2889235491\n              hang_time\nheight        0.1884978\nweight       -0.1426521\nbody_fat_pct -0.4844682\ngrip_left     0.3455952\nsit_forward   0.2889235\nhang_time     1.0000000\n\n\n표본 상관계수 행렬을 보면 다양한 상관관계가 나타나는데 이러한 관계를 더 자세하게 보기위하여 산점도 행렬(scatterplot matrix)로 시각화 하면 더 유용한 정보를 얻을 수 있다.\n\npairs(df, pch=19, col='blue', cex=0.1)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>확률벡터와 다변량 정규분포</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-dist.html#다변량-정규분포",
    "href": "qmd/multivar-dist.html#다변량-정규분포",
    "title": "1  확률벡터와 다변량 정규분포",
    "section": "1.3 다변량 정규분포",
    "text": "1.3 다변량 정규분포\n일변량 확률변수 \\(X\\)가 평균이 \\(\\mu\\) 이고 분산이 \\(\\sigma^2\\)인 정규분포를 따른다면 다음과 같이 나타내고 \\[ X \\sim N(\\mu, \\sigma^2 ) \\] 확률밀도함수 \\(f(x)\\) 는 다음과 같이 주어진다.\n\\[ f(x) = (2 \\pi \\sigma^2)^{-1/2} \\exp \\left ( - \\frac{(x-\\mu)^2}{2} \\right ) \\]\n\n1.3.1 확률 밀도 함수\n\\(p\\)-차원 확률벡터 \\(\\pmb X\\)가 평균이 \\(\\pmb \\mu\\) 이고 공분산이 \\(\\pmb \\Sigma\\)인 다변량 정규분포를 따른다면 다음과 같이 나타내고 \\[ \\pmb X \\sim N_p(\\pmb \\mu, \\pmb \\Sigma ) \\] 확률밀도함수 \\(f(\\pmb x)\\) 는 다음과 갇이 주어진다.\n\\[ f(\\pmb x) = (2 \\pi)^{-p/2} | \\pmb \\Sigma|^{-1/2}\n   \\exp \\left ( - \\frac{(\\pmb x-\\pmb \\mu) \\pmb \\Sigma^{-1}(\\pmb x-\\pmb \\mu)^t}{2} \\right ) \\]\n예를 들어 \\(2\\)-차원 확률벡터 \\(\\pmb X=(X_1, X_2)^t\\)가 평균이 \\(\\pmb \\mu=(\\mu_1,\\mu_2)^t\\) 이고 공분산 \\(\\pmb \\Sigma\\)가 다음과 같이 주어진\n\\[\n\\pmb \\Sigma =\n  \\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} \\\\\n\\sigma_{12} & \\sigma_{22}\n\\end{bmatrix}\n\\]\n이변량 정규분포를 따른다면 확률밀도함수 \\(f(\\pmb x)\\)에서 \\(\\exp\\)함수의 인자는 다음과 같이 주어진다. \\[\n\\begin{aligned}\n&(\\pmb x-\\pmb \\mu) \\pmb \\Sigma^{-1}(\\pmb x-\\pmb \\mu)^t\n= \\\\\n&-\\frac{1}{2 (1-\\rho^2)}\n\\left [\n  \\left ( \\frac{(x_1-\\mu_1)^2}{\\sigma_{11}} \\right )\n  +\\left ( \\frac{(x_2-\\mu_2)^2}{\\sigma_{22}} \\right )\n  -2 \\rho \\left ( \\frac{(x_1-\\mu_1)}{\\sqrt{\\sigma_{11}}} \\right )\n  \\left ( \\frac{(x_2-\\mu_2)}{\\sqrt{\\sigma_{22}}} \\right )\n  \\right ]\n\\end{aligned}\n\\]\n그리고 \\(p=2\\) 인 경우 확률밀도함수의 상수부분은 다음과 같이 주어진다.\n\\[ (2 \\pi)^{-p/2} | \\pmb \\Sigma|^{-1/2} = \\frac{1}{ 2 \\pi \\sqrt{\\sigma_{11} \\sigma_{22} (1-\\rho^2)}} \\]\n여기서 \\(\\rho = \\sigma_{12} / \\sqrt{\\sigma_{11} \\sigma_{22}}\\)\n\n\n\n\n\n\n다변량 정규분포에서 독립과 공분산\n\n\n\n다변량 정규분포에서 공분산이 0인 두 확률 변수는 독립이다. \\[ \\sigma_{ij} = 0 \\leftrightarrow X_i \\text{ and } X_j \\text{ are independent} \\]\n참고로 정규분포가 아닌 다른 분포의 경우 공분산이 0인 두 확률 변수는 독립이 아닐 수 있다.\n\n\n\n\n1.3.2 예제-국민체력100\n이제 위에서 샇펴본 국민체력100 자료에서 청소년 남자의 키(height)와 몸무게(weight) 가 이변량 정규분포를 따른다고 가정하고 확률밀도 함수를 그려보자.\n\n# 필요한 패키지 로드\nlibrary(mvtnorm)\nlibrary(plotly)\n\n# 국민체력100 자료에서 남자만 선택하여 데이터프레임 df 생성, 키와 몸무게 변수만 선택와\ndf &lt;- physical100_df %&gt;% \n  filter(sex == \"남성\") %&gt;%\n  select(height, weight)\n\n#  패키지 dplyr의 summarise()와 across() 함수를 사용하여 각 열의 평균 계산\nsample_mean_vector &lt;- df %&gt;%\n  summarise(across(everything(), \\(x) mean(x, na.rm = TRUE))) %&gt;%\n  unlist()\nsample_mean_vector\n\n   height    weight \n172.04515  69.71155 \n\n# 표본 공분산 행렬 계산\nsample_cov_matrix &lt;- cov(df, use = \"complete.obs\")\nsample_cov_matrix\n\n         height    weight\nheight 47.51166  54.80339\nweight 54.80339 243.09372\n\n# 이변량 정규분포의 확률밀도함수 계산\n# 키와 몸무게의 평균에서 표분편차 3배의 범위의 값을 100개로 나누어 x,y 축 생성\nx1_seq &lt;- seq(sample_mean_vector[1]-3* sqrt(sample_cov_matrix[1,1]), sample_mean_vector[1]+3* sqrt(sample_cov_matrix[1,1]), length.out = 100)\nx2_seq &lt;- seq(sample_mean_vector[2]-3* sqrt(sample_cov_matrix[2,2]), sample_mean_vector[2]+3* sqrt(sample_cov_matrix[2,2]), length.out = 100)\ngrid &lt;- expand.grid(height = x1_seq, weight = x2_seq)\n\n# 확률밀도함수 계산 (z축의 값)\ngrid$z &lt;- dmvnorm(grid, mean = sample_mean_vector, sigma = sample_cov_matrix)\n\n# z를 행렬로 변환 (surface plot용)\nz_matrix &lt;- matrix(grid$z, nrow = length(x1_seq), ncol = length(x2_seq))\n\n다음은 위에서 얻어진 확률밀도 함수를 3차원 surface plot으로 나타낸 것이다.\n\n# 이변량 정규분포의 확률밀도 함를 3D Surface Plot\nplot_ly(\n  x = x1_seq, \n  y = x2_seq, \n  z = z_matrix\n) %&gt;% add_surface() %&gt;%\n  layout(\n    title = \"Bivariate Normal PDF (Surface)\",\n    scene = list(\n      xaxis = list(title = \"키\"),\n      yaxis = list(title = \"몸무게\"),\n      zaxis = list(title = \"Density\")\n    )\n  )\n\n\n\n\n\n아래 그림은 표본으로 부터 얻어진 확률밀도 함수를 2차원 등고선(contour)으로 나타낸 그림이다.\n\nplot_ly(\n  x = x1_seq,\n  y = x2_seq,\n  z = z_matrix\n) %&gt;%\n  add_contour(\n    contours = list(\n      coloring = \"heatmap\",\n      showlabels = TRUE\n    )\n  ) %&gt;%\n  layout(\n    title = \"Bivariate Normal PDF (Contour)\",\n    xaxis = list(title = \"키\"),\n    yaxis = list(title = \"몸무게\")\n  )\n\n\n\n\n\n\n\n1.3.3 조건부 분포\n다변량 정규분포 \\(N(\\pmb \\mu, \\pmb \\Sigma)\\)를 따르는 확률벡터 \\(\\pmb X\\)를 다음과 같이 두 부분으로 나누면\n\\[\n  \\pmb X =\n    \\begin{bmatrix}\n  \\pmb X_1 \\\\\n  \\pmb X_2\n  \\end{bmatrix}, \\quad\n  \\pmb X_1 =\n    \\begin{bmatrix}\n  \\pmb X_{11} \\\\\n  \\pmb X_{12} \\\\\n  \\pmb \\vdots \\\\\n  \\pmb X_{1p}\n  \\end{bmatrix}, \\quad\n  \\pmb X_2=\n    \\begin{bmatrix}\n  \\pmb X_{21} \\\\\n  \\pmb X_{22} \\\\\n  \\pmb \\vdots \\\\\n  \\pmb X_{2q}\n  \\end{bmatrix}\n  \\]\n각각 다변량 정규분포를 따르고 다음과 같이 나타낼 수 있다.\n\\[\n  \\begin{bmatrix}\n  E(\\pmb X_1) \\\\\n  E(\\pmb X_2)\n  \\end{bmatrix}\n  =\n    \\begin{bmatrix}\n  \\pmb \\mu_1 \\\\\n  \\pmb \\mu_2\n  \\end{bmatrix}\n  , \\quad\n  \\begin{bmatrix}\n  V(\\pmb X_1) & Cov(\\pmb X_1, X_2) \\\\\n  Cov(\\pmb X_2 X_1) & V(\\pmb X_2)\n  \\end{bmatrix}\n  =\n    \\begin{bmatrix}\n  \\pmb \\Sigma_{11} & \\pmb \\Sigma_{12} \\\\\n  \\pmb \\Sigma^t_{12} & \\pmb \\Sigma_{22}\n  \\end{bmatrix}\n  \\]\n\\[  \\pmb X =\n    \\begin{bmatrix}\n  \\pmb X_1 \\\\\n  \\pmb X_2\n  \\end{bmatrix}\n  \\sim\n  N_{p+q} \\left (\n    \\begin{bmatrix}\n    \\pmb \\mu_1 \\\\\n    \\pmb \\mu_2\n    \\end{bmatrix}\n    ,\\begin{bmatrix}\n    \\pmb \\Sigma_{11} & \\Sigma_{12} \\\\\n    \\pmb \\Sigma^t_{12} & \\Sigma_{22}\n    \\end{bmatrix}\n    \\right )\n  \\]\n확률벡터 \\(\\pmb X_2 = \\pmb x_2\\)가 주어진 경우 \\(\\pmb X_1\\)의 조건부 분포는 \\(p\\)-차원 다변량 정규분포를 따르고 평균과 공분산은 다음과 같다.\n\\[\n  E(\\pmb X_1 | \\pmb X_2 = \\pmb x_2 ) = \\pmb \\mu_1 + \\pmb \\Sigma_{12} \\pmb \\Sigma^{-1}_{22} (\\pmb \\mu_2 - \\pmb x_2), \\quad\n  V(\\pmb X_1 | \\pmb X_2 = \\pmb x_2 )  = \\pmb \\Sigma_{11} -\\pmb \\Sigma_{12} \\pmb \\Sigma^{-1}_{22} \\pmb \\Sigma^t_{12}\n  \\]\n만약 \\(X_2 = x_2\\)가 주어졌을 때 \\(X_1\\)의 조건부 분포는 정규분포이고 평균과 분산은 다음과 같이 주어진다.\n\\[\n  E( X_1 |  X_2 =  x_2 ) =  \\mu_1 +  \\frac{\\sigma_{12}}{\\sigma_{22}} ( \\mu_2 -  x_2)  = \\mu_1 +  \\rho \\frac{\\sqrt{\\sigma_{11}}}{\\sqrt{\\sigma_{22}}} ( \\mu_2 -  x_2) \\]\n\\[\n  V( X_1 |  X_2 =  x_2 )  =  \\sigma_{11} - \\frac{\\sigma^2_{12}}{\\sigma_{22}}  = \\sigma_{11}(1-\\rho^2)\n\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>확률벡터와 다변량 정규분포</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-vis.html",
    "href": "qmd/multivar-vis.html",
    "title": "2  다변량 자료의 시각화",
    "section": "",
    "text": "2.1 산점도 그림\n일반적으로 많이 사용하는 회귀모형(regression model) 은 반응변수와 이에 영향을 주는 설명변수들의 관계를 분석하는 모형이다. 따라서 주로 회귀모형에서 시각화 방법은 반응변수와 설명변수의 관계를 나타내는 그림이며 주로 2개의 변수의 관계를 파악하는 산점도 그림 (scatter plot) 이 많이 사용된다.\n다변량 분석은 여러 개의 확률 변수들의 관계를 분석하는 통계 기법이다. 회귀모형과 다른 점은 주로 예측에 관심이 있는 반응변수가 없는 것이며 따라서 분석의 특성상 3개 이상의 변수의 관계를 한 그림에 시각화하는 방밥이 필요하다.\n이 장에서는 다변량 분석에서 여러 개의 변수들의 관계를 동시에 시각화 방법들을 알아보려고 한다.\n앞에서 언급한 것과 같이 3개의 변수를 산점도에 나타내려면 x 축, y 축 과 더불어서 점의 특성(색깔, 모양 등)을 이용할 수 있다.\nR 패키지 gapminder 에 포함된 gapminder 데이터는 전 세계 여러 국가의 경제, 보건 지표를 연도별로 기록한 공개 자료이다. 원본은 [Gapminder 재단]{https://www.gapminder.org/} 에서 제공한다. gapminder 데이터는 1952년부터 2007년까지 5년 단위로 측정한 각 국가별 경제 수준과 건강 상태를 시계열로 비교 가능하게 정리한 자료이다.\nhead(gapminder::gapminder)\n\n# A tibble: 6 × 6\n  country     continent  year lifeExp      pop gdpPercap\n  &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n1 Afghanistan Asia       1952    28.8  8425333      779.\n2 Afghanistan Asia       1957    30.3  9240934      821.\n3 Afghanistan Asia       1962    32.0 10267083      853.\n4 Afghanistan Asia       1967    34.0 11537966      836.\n5 Afghanistan Asia       1972    36.1 13079460      740.\n6 Afghanistan Asia       1977    38.4 14880372      786.\n이제 gapminder 데이터에서 2007년 자료를 이용하여 1인당 국민소득(gdpPercap)과 기대수명(lifeExp)의 관계를 산점도로 나타내고, 대륙(continent)에 따라 점의 크기로 다르게 나타내는 그림을 그려보자. 이렇게 점의 크기를 변수의 값에 따라 변하는 산점도를 버블 차트(bubble chart) 라고 한다.\ngapminder::gapminder %&gt;%\n  filter(year == 2007) %&gt;%\n  ggplot(aes(x = gdpPercap, y = lifeExp, size=pop)) +\n  geom_point(alpha = 0.5, color=\"blue\") +\n  labs(title = \"1인당 국민소득과 기대수명의 관계 (2007년)\",\n       x = \"1인당 국민소득\",\n       y = \"기대수명\",\n       size = \"인구수\") +\n  theme(text = element_text(family = \"noto\")) # 한글 폰트 설정(lib(showtext) 패키지 필요)\n위의 그림을 보면 1인당 국민소득과 기대수명의 관계가 선형적이지 않음을 알 수 있다. 따라서 x 축을 로그 스케일로 변환하여 다시 그려보자.\ngapminder::gapminder %&gt;%\n  filter(year == 2007) %&gt;%\n  ggplot(aes(x = gdpPercap, y = lifeExp, size=pop)) +\n  geom_point(alpha = 0.5, color=\"blue\") + # alpha는 점의 투명도\n  scale_x_log10() + # x축을 로그 스케일로 변환\n  labs(title = \"1인당 국민소득과 기대수명의 관계 (2007년)\",\n       x = \"1인당 국민소득 (로그 스케일)\",\n       y = \"기대수명\",\n       size = \"인구수\") +\n  theme(text = element_text(family = \"noto\"))\n위의 그림에서 나라가 속한 대륙에 따라 점의 색깔을 다르게 나타내어 보자. 많은 경우 자료는 특정 그룹별로 분석하는 경우가 많기 떄문에 그룹을 시각적으로 나타내는 것이 중요하다.\ngapminder::gapminder %&gt;%\n  filter(year == 2007) %&gt;%\n  ggplot(aes(x = gdpPercap, y = lifeExp, size=pop, color=continent)) +\n  geom_point(alpha = 0.5) +\n  scale_x_log10() + # x축을 로그 스케일로 변환\n  labs(title = \"1인당 국민소득과 기대수명의 관계 (2007년)\",\n       x = \"1인당 국민소득 (로그 스케일)\",\n       y = \"기대수명\",\n       size = \"인구수\",\n       color = \"대륙\") +\n  theme(text = element_text(family = \"noto\"))\n이렇게 그룹화하여 시각화 하는 경우 그룹마다 산점도를 따로 나타내는 방법으로 facet 기능을 사용할 수 있다. facet 기능은 ggplot2 패키지에서 제공하는 기능으로 facet_wrap() 함수와 facet_grid() 함수가 있다.\ngapminder::gapminder %&gt;%\n  filter(year == 2007) %&gt;%\n  ggplot(aes(x = gdpPercap, y = lifeExp, size=pop)) +\n  geom_point(alpha = 0.5, color=\"blue\") +\n  scale_x_log10() + \n  labs(title = \"1인당 국민소득과 기대수명의 관계 (2007년)\",\n       x = \"1인당 국민소득 (로그 스케일)\",\n       y = \"기대수명\",\n       size = \"인구수\") +\n  facet_wrap(~ continent) + # 대륙별로 산점도 따로 표시\n  theme(text = element_text(family = \"noto\"))\n위의 그림에서 아시아에 속한 나라들만 선택해서 점의 크기를 인구에 비례하게 하고 또한 나라의 이름을 표시해보자.\ngapminder::gapminder %&gt;%\n  filter(year == 2007, continent == \"Asia\") %&gt;%\n  ggplot(aes(x = gdpPercap, y = lifeExp, size=pop, label=country)) +\n  geom_point(alpha = 0.5, color=\"blue\") +\n  geom_text(vjust = -1, size=3) + # 나라 이름 표시\n  scale_x_log10() + # x축을 로그 스케일로 변환\n  labs(title = \"1인당 국민소득과 기대수명의 관계 (2007년, 아시아 국가)\",\n       x = \"1인당 국민소득 (로그 스케일)\",\n       y = \"기대수명\",\n       color = \"대륙\") +\n  theme(text = element_text(family = \"noto\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>다변량 자료의 시각화</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-vis.html#산점도-그림",
    "href": "qmd/multivar-vis.html#산점도-그림",
    "title": "2  다변량 자료의 시각화",
    "section": "",
    "text": "변수명\n설명\n\n\n\n\ncountry\n국가 이름\n\n\ncontinent\n대륙 이름\n\n\nyear\n연도\n\n\nlifeExp\n기대수명 (average life expectancy)\n\n\npop\n인구 (population)\n\n\ngdpPercap\n1인당 국민소득 (gross domestic product per capita)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>다변량 자료의 시각화</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-vis.html#상관계수-행렬",
    "href": "qmd/multivar-vis.html#상관계수-행렬",
    "title": "2  다변량 자료의 시각화",
    "section": "2.2 상관계수 행렬",
    "text": "2.2 상관계수 행렬\n다변량 분석에서 상관계수는 여러 개의 변수들의 관계를 파악하는 가장 기본적인 통계량으로서 시각화를 이용하면 더 쉽게 이해할 수 있다.\n상관계수 행렬(correlation matrix)은 여러 변수들 간의 상관계수를 한눈에 볼 수 있도록 정리한 그림이다. 상관계수 행렬을 시각화하는 방법으로는 히트맵(heatmap)이나 페어 플롯(pair plot) 등이 있다.\n상관계수 행렬에 대한 예제는 앞 장에서 살펴본 국민체력100 자료를 이용하고자 한다.\n먼저 가장 감단한 방법인 pair() 함수를 이용하여 페어 플롯을 그려보자. pair() 함수는 R에 기본으로 포함된 함수로서 여러 변수들 간의 산점도와 히스토그램을 한눈에 볼 수 있도록 그려준다.\n\nload(here(\"data\", \"physical100.RData\"))\n# 국민체력100 자료에서 남자만 선택하여 데이터프레임 df 생성\ndf &lt;- physical100_df %&gt;% \n  filter(sex == \"남성\") %&gt;%\n  select(height, weight, body_fat_pct, grip_left, sit_forward,hang_time)\n\n# pair() 함수를 이용하여 상관계수 행렬 그리기\npairs(df, pch=19, cex=0.1)\n\n\n\n\n\n\n\n\n위와 같은 상관계수 산점도 행렬에 다음과 같이 회귀 직선을 추가하여 변수들 간의 관계를 더 명확히 나타낼 수 있다. 다음 코드는 panel 인수를 이용하여 각 산점도에 회귀 직선을 추가하는 방법을 보여준다.\n\npairs(\n  df,\n  panel = function(x, y) {\n    points(x, y, pch=19, cex=0.1)\n    abline(lm(y ~ x), col = \"red\", lwd = 1.5)  # 선형회귀 직선\n  }\n)\n\n\n\n\n\n\n\n\n위의 상관계수 행렬 그림에 좀 더 유용한 정보를 추가하는 다양한 방법들이 있다. 예를 들어, GGally 패키지의 ggpairs() 함수를 이용하면 상관계수 행렬에 상관계수 값과 각 변수에 대한 히스토그램을 추가하여 볼수 있다.\n\nggpairs(df,\n        upper = list(continuous = wrap(\"cor\", size = 4)), # 상관계수 표시\n        lower = list(continuous = wrap(\"points\", alpha=0.3, size=0.5)), # 산점도\n        diag = list(continuous = wrap(\"barDiag\", fill=\"lightblue\"))) + # 히스토그램\n  theme(text = element_text(family = \"noto\"))\n\n\n\n\n\n\n\n\n최근에는 상관계수 행렬을 히트맵(heatmap)으로 나타내기도 한다. 히트맵은 색깔로 값의 크기를 나타내는 그림으로서 상관계수 행렬을 히트맵으로 나타내면 변수들 간의 관계를 쉽게 파악할 수 있다.\n특히, 변수의 개수가 매우 많은 경우 산점도를 이용한 상관계수 행렬은 시각적으로 분석이 어렵기 때문에 히트맵으로 나타내는 것이 더 유용할 수 있다. 패키지 pheatmap 의 pheatmap() 함수를 이용하여 상관계수 행렬을 히트맵으로 나타내보자. pheatmap() 함수의 유용한 점은 상관계수가 큰 변수끼리 군집화(clustering)하여 시각화할 수 있다는 점이다\n자료는 국민체력100 자료에서 남자에 대한 모든 변수를 이용한 자료를 이용한다.\n\n# 국민체력100 자료에서 남자만 선택하여 데이터프레임 df 생성\ndf &lt;- physical100_df %&gt;% \n  filter(sex == \"남성\") %&gt;%\n  select(-sex)\n\n# 상관계수 행렬 계산\ncor_mat &lt;- cor(df, use=\"pairwise.complete.obs\") # 결측치가 있는 경우 pairwise로 계산\n\n# 히트맵 그리기\npheatmap::pheatmap(cor_mat,  display_numbers = TRUE, number_format = \"%.2f\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>다변량 자료의 시각화</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-test.html",
    "href": "qmd/multivar-test.html",
    "title": "3  다변량 가설 검정",
    "section": "",
    "text": "3.1 t-검정\n이번 장에서는 다변량 벡터의 자료에 대한 가설 검정법을 간단히 학습한다. 다변량에서 평균에 대한 검정은 일변량 벡터에서의 t-겁정의 개념을 확장하여 이해하는 것이 중요하다. 일변량 확률 분포에서 두 그룹의 평균을 비교하는 t-겁정 방법을 다변량으로 확장하는 방법을 단계별로 살펴보자.\n참고로 이 장에서는 두 그룹에 대한 분산 또는 공분산이 같다고 가정한다. 공분산이 다른 경우는 아래 방법들을 확장해서 적용할 수 있지만 좀 더 복잡한 통계적 추론이 필요하다.\n기초통계학에서 나오는 가장 기본적이고 자주 쓰이는 가설검정 방법은 두 집단의 평균의 차이를 검정하는 t-검정(t-test)이다.\n두 집단이 평균이 다르고 분산이 동일한 정규분포 \\(N(\\mu_1, \\sigma^2)\\), \\(N(\\mu_2, \\sigma^2)\\)를 따른다고 가정하고 다음과 같이 각각 \\(n_1, n_2\\)개의 독립 표본을 얻었다고 하자.\n\\[\nX_{1}, X_{2}, \\dots, X_{n_1} \\sim N(\\mu_1, \\sigma^2), \\quad Y_{1}, Y_{2}, \\dots, Y_{n_2} \\sim N(\\mu_2, \\sigma^2)\n\\]\n위의 가설을 다음과 같은 t-통계량을 이용하여 검정할 수 있다.\n\\[\nt_0 =\\frac {\\bar X -\\bar Y } {  S_p \\sqrt{1/n_1 + 1/n_2}}\n\\tag{3.1}\\]\n여기서 \\(\\bar X\\), \\(\\bar Y\\)은 각 그룹의 표본 평균이다. 또한 \\(S_p^2\\) 은 두 집단의 공통분산 추정량(pooled variance estimator)이며 다음과 같이 계산한다.\n\\[ \\hat \\sigma^2 = S_p^2 =  \\frac { \\sum_{i=1}^{n_1} (X_{i} -\\bar X)^2 + \\sum_{i=1}^{n_2} (Y_{i} -\\bar Y)^2 } { n_1 + n_2 -2} \\]\n식 3.1 의 t-검정 통계량의 분자는 집단 간의 평균의 차이를 나타낸다. 즉 \\(\\bar X-\\bar Y\\)는 두 집단의 표본 평균의 차이를 추정하는 양이고 그 차이가 크면 클수록 두 집단의 모평균의 차이 \\(\\mu_1 - \\mu_2\\)가 크다는 것을 의미한다.\nt-검정 통계량의 분모는 두 집단의 공통분산 추정량 \\(\\hat \\sigma^2 =S_p^2\\)에 비례한다. 즉 집단 내의 변동을 반영하는 \\(S_p^2\\) 이 크면 클수록 t-검정 통계량은 그 크기가 작아져서 두 그룹 간에 차이가 있다는 증거가 약해진다.\n정리해보면 t-검정 통계량은 집단 간의 변동(between-group variation)을 집단 내의 변동(within-group variation) 으로 나누어준 값이다. 다른 말로 급간 변동과 급내 변동을 사용하기도 한다.\n이제 t-검정 통계량을 제곱하면 다음과 같이 표현할 수 있다.\n\\[  \nt_0^2 =\\frac { (\\bar X -\\bar Y)^2 } { S_p^2 (1/n_1 + 1/n_2)} = \\frac{\\text{between-group variation}} {\\text{within-group variation}}\n\\tag{3.2}\\]\n통계학에서 등장하는 평균에 대한 겁정 통계량은 식 식 3.2 과 같이 그룹간 변동과 그룹내 변동의 비(ratio)로 이루어 진 경우가 많다. 이제 더 나아가 검정 통계량의 다른 해석으로 통계적 거리의 의미를 살펴보자.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>다변량 가설 검정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-test.html#통계적-거리",
    "href": "qmd/multivar-test.html#통계적-거리",
    "title": "3  다변량 가설 검정",
    "section": "3.2 통계적 거리",
    "text": "3.2 통계적 거리\n다변량 벡터의 평균에 대한 가설 검정을 위해서 다변량 벡터의 통계적 거리(statistical distance)의 개념에 대해서 알아보자.\n먼저 일변량 벡터의 가설검정에 나타나는 t-검정 통계량의 형태를 식 3.2 으로 나타내면 다음과 같은 사실을 알 수 있다.\n\n분자는 두 그룹의 평균에 대한 추정량의 공간적 거리, 즉 \\(\\bar X  - \\bar Y\\) 로서 두 그룹의 평균이 유클리디안 공간(Euclidean distance)에서 얼마나 떨어져 있는 가를 나타낸다. 검정 통계량에서는 거리의 제곱을 사용하였다.\n분모는 두 그룹의 거리에 대한 통계적 불확실성을 반영한다. 이는 추정량의 분산 \\(S^2_p\\) 를 통해서 나타내며, \\(S^2_p\\) 가 커지면 공간적인 거리가 동일해도 통계적인 의미에서의 거리는 줄어드는 것이다.\n\n이제 두 p-차원 확률 벡터 \\(\\pmb X\\) 와 \\(\\pmb Y\\)에 대한 공간적 거리 \\(d( \\pmb X, \\pmb Y)\\) 는 다음과 같이 정의된다.\n\\[\nd( \\pmb X, \\pmb Y)^2 =  (\\pmb X - \\pmb Y)^t (\\pmb X - \\pmb Y)\n\\] 이제 두 확률 벡터의 차이 \\(\\pmb X - \\pmb Y\\)의 불확실성을 나타내는 공분산 행렬을 \\(\\pmb \\Sigma\\) 하면, 확률 벡터의 통계적 거리(statistical distnace 또는 Mahalanobis distance) 는 다음과 같이 정의 된다.\n\\[\nd( \\pmb X, \\pmb Y | {\\pmb \\Sigma})^2 =   (\\pmb X - \\pmb Y)^t  {\\pmb \\Sigma}^{-1} (\\pmb X - \\pmb Y)\n\\tag{3.3}\\]\n여기서 \\(\\Sigma^{-1}\\) 은 공분산 행렬 \\(\\Sigma\\) 의 역행렬(inverse matrix)이다.\n식 3.3 의 통계적 거리는 일변량에서 사용되는 t-검정 통계량의 형태를 다변량 확률변수에 대해서 확장할 수 있는 방법을 제공해 준다.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>다변량 가설 검정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-test.html#호텔링의-t2-검정",
    "href": "qmd/multivar-test.html#호텔링의-t2-검정",
    "title": "3  다변량 가설 검정",
    "section": "3.3 호텔링의 \\(T^2\\) 검정",
    "text": "3.3 호텔링의 \\(T^2\\) 검정\n이제 다변량 벡터의 평균에 대한 검정을 위해서 위에서 정의한 통계적 거리를 이용하여 호텔링의 \\(T^2\\) 검정(Hotelling’s \\(T^2\\) test)을 살펴보자.\n확률 벡터 \\(\\pmb X\\) 과 \\(\\pmb Y\\) 가 평균이 각각 \\(\\pmb \\mu_1\\), \\(\\pmb \\mu_2\\) 이고 공분산이 \\(\\pmb \\Sigma\\) 인 p-차원 다변량 정규 분포를 따른다고 가정하자.\n\\[ \\pmb X \\sim N_p(\\pmb \\mu_1, \\pmb \\Sigma), \\quad \\pmb Y \\sim N_p(\\pmb \\mu_2, \\pmb \\Sigma) \\]\n호텔링의 \\(T^2\\) 검정은 두 그룹의 다변량 평균 벡터가 같은지에 대한 가설검정 방법이다. 즉 다음과 같은 가설을 검정한다.\n\\[\nH_0: \\pmb \\mu_1 = \\pmb \\mu_2\n\\]\n이제 가설 검정을 위하여 두 그룹에서 각각 \\(n_1, n_2\\)개의 다변량 표본이 관측되었다고 하자.\n\\[\n\\pmb X_1, \\pmb X_2, \\dots, \\pmb X_{n_1} \\sim_{IID} N(\\pmb \\mu_1, \\pmb \\Sigma), \\quad \\pmb Y_1, \\pmb Y_2, \\dots, \\pmb Y_{n_2} \\sim_{IID} N(\\pmb \\mu_2, \\pmb \\Sigma)\n\\]\n평균 벡터에 대한 추정량은 각 표본 평균 \\(\\bar {\\pmb X}\\) 과 \\(\\bar {\\pmb Y}\\) 이고 공분산 행렬의 합동 추정량 \\(\\pmb {S}_p\\) 을 다음과 같이 정의한다.\n\\[\n\\pmb S_p = \\hat {\\pmb \\Sigma} =\n\\frac{1}{n_1 + n_2 -2} \\left( \\sum_{i=1}^{n_1} (\\pmb X_i - \\bar {\\pmb X})(\\pmb X_i - \\bar {\\pmb X})^t + \\sum_{i=1}^{n_2} (\\pmb Y_i - \\bar {\\pmb Y})(\\pmb Y_i - \\bar {\\pmb Y})^t \\right)\n\\tag{3.4}\\]\n두 그룹의 평균벡터가 같은지에 대한 검정을 위하여 호텔링의 \\(T^2\\) 검정 통계량은 식 3.3 의 형태로 다음과 같이 정의된다.\n\\[\n\\begin{aligned}\nT^2 & = (\\bar {\\pmb X} - \\bar {\\pmb Y})^t \\left [ \\left ( \\frac{1}{n_1} + \\frac{1}{n_2} \\right )  \\pmb S_p \\right ]^{-1} (\\bar {\\pmb X} - \\bar {\\pmb Y}) \\\\\n& = \\frac{n_1 n_2}{n_1 + n_2} (\\bar {\\pmb X} - \\bar {\\pmb Y})^t \\pmb S_p^{-1} (\\bar {\\pmb X} - \\bar {\\pmb Y})\n\\end{aligned}\n\\tag{3.5}\\]\n위의 호텔링의 \\(T^2\\) 통계량은 두 그룹의 평균 벡터 \\(\\bar {\\pmb X}\\) 와 \\(\\bar {\\pmb Y}\\) 의 차이에 대한 통계적 거리(statistical distance)를 나타낸다. 즉 두 그룹의 평균 벡터의 차이 \\(\\bar {\\pmb X} - \\bar {\\pmb Y}\\) 에 대한 제곱항을 그 차이의 불확실성을 나타내는 공분산 행렬 \\(\\pmb S\\) 의 역행렬로 나누어준 값이다. 일변량에서 t-검정과 동일하게 식 3.5 의 값이 커지면 귀무가설에 반하는 정도가 커지는 것이다.\n호텔링 통계량 \\(T^2\\) 은 귀무가설이 참인 경우, 즉 \\(\\pmb \\mu_1 = \\pmb \\mu_2\\) 일때 자유도가 각각 \\(p\\) 와 \\(n_2+n_2-p-1\\) 을 가지는 F-분포를 따른다. 이 때 \\(p\\) 는 확률 벡터의 차원이다.\n\\[\n\\frac{n_1 + n_2 - p -1}{(n_1 + n_2 -2)p} T^2 \\sim F_{p, n_1 + n_2 - p -1} \\quad \\text{ if } H_0: \\pmb {\\mu_1} = \\pmb {\\mu_2} \\text{ is true}\n\\] 따라서 유의수준 \\(\\alpha\\) 에서 귀무가설을 검정하기 위해서는 다음과 같이 F-분포에서 기각역을 구하여 \\(T^2\\) 값과 비교한다.\n\\[\n\\text{Reject } H_0 \\quad  \\text{ if } \\frac{n_1 + n_2 - p -1}{(n_1 + n_2 -2)p} T^2 &gt; F_{\\alpha; p, n_1 + n_2 - p -1}\n\\] 또는 다음과 같이 계산한 p-값(p-value) 가 유의수준 \\(\\alpha\\) 보다 작으면 귀무가설을 기각한다.\n\\[\n\\text{p-value } = P \\left ( F_{p, n_1 + n_2 - p -1} &gt; \\frac{n_1 + n_2 - p -1}{(n_1 + n_2 -2)p} T^2 \\right )\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>다변량 가설 검정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-test.html#예제-두-그룹의-평균벡터-검정",
    "href": "qmd/multivar-test.html#예제-두-그룹의-평균벡터-검정",
    "title": "3  다변량 가설 검정",
    "section": "3.4 예제: 두 그룹의 평균벡터 검정",
    "text": "3.4 예제: 두 그룹의 평균벡터 검정\n이 예제에서는 다변량 통계학에서 가장 자주 사용되는 피셔의 아이리스(Fisher’s Iris) 자료를 이용하여 두 그룹의 평균벡터에 대한 검정을 배워보자.\nR에 내장된 iris(Fisher’s Iris) 자료는 1930년대 식물학자 Edgar Anderson 가 채집하고 측정한 붓꽃(iris) 데이터를 통계학자 R. A. Fisher(1936) 가 선형판별분석(Linear Discrimination Anslysis) 예제로 분석하면서 널리 알려졌다. 총 3개 종(Setosa, Versicolor, Virginica) 에서 각각 50개 표본으로 구성된 균형 자료(balanced data)이며 붓꽃의 특성을 나타내는 4개의 변수(단위: cm)로 구성되어 있다.\n\nSepal.Length: 꽃받침 길이\nSepal.Width : 꽃받침 너비\nPetal.Length: 꽃잎 길이\nPetal.Width : 꽃잎 너비\nSpecies: 범주형(세 종: setosa, versicolor, virginica)\n\n\ndata(iris)\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n이제 iris 자료에서 versicolor 와 virginica 두 종(각 50개 표본, \\(p=4\\) 변수)로 두 종에 대한 평균벡터가 동등한지 검정을 R 프로그램으로 수행해보자. 먼저 두 개의 종만 포함하는 자료를 만들고 표본 통계량을 구해보자.\n\n# 패키지\n#install.packages(c(\"Hotelling\", \"biotools\"), dependencies = TRUE)\n##library(Hotelling)\n#library(biotools)\n\ndf &lt;- iris %&gt;% \n      filter(Species %in% c(\"versicolor\", \"virginica\"))\n\ndf$Species &lt;- droplevels(df$Species)  # 두 수준만\n\nhead(df)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1          7.0         3.2          4.7         1.4 versicolor\n2          6.4         3.2          4.5         1.5 versicolor\n3          6.9         3.1          4.9         1.5 versicolor\n4          5.5         2.3          4.0         1.3 versicolor\n5          6.5         2.8          4.6         1.5 versicolor\n6          5.7         2.8          4.5         1.3 versicolor\n\n# 각 그룹의 표본 크기\nn1 &lt;- sum(df$Species==\"versicolor\")\nn2 &lt;- sum(df$Species==\"virginica\")\np &lt;- ncol(df)-1  # 변수 개수\nn1; n2; p\n\n[1] 50\n\n\n[1] 50\n\n\n[1] 4\n\n\n다음으로 두 그룹에 대한 평균 벡터와 두 그룹의 평균의 차이를 나타내는 벡터를 구해보자.\n\n# 그룹별 4개의 변수에 대한 평균 \nmean_vec &lt;- df %&gt;% group_by(Species) %&gt;%\n       summarise(across(Sepal.Length:Petal.Width, list(mean=mean), .names=\"{col}_{fn}\"))\nmean_vec\n\n# A tibble: 2 × 5\n  Species  Sepal.Length_mean Sepal.Width_mean Petal.Length_mean Petal.Width_mean\n  &lt;fct&gt;                &lt;dbl&gt;            &lt;dbl&gt;             &lt;dbl&gt;            &lt;dbl&gt;\n1 versico…              5.94             2.77              4.26             1.33\n2 virgini…              6.59             2.97              5.55             2.03\n\nmean_x &lt;- mean_vec %&gt;%\n  filter(Species==\"versicolor\") %&gt;%\n  select(Sepal.Length_mean, Sepal.Width_mean, Petal.Length_mean, Petal.Width_mean) %&gt;%\n  as.matrix()\n\nmean_y &lt;- mean_vec %&gt;%\n  filter(Species==\"virginica\") %&gt;%\n  select(Sepal.Length_mean, Sepal.Width_mean, Petal.Length_mean, Petal.Width_mean) %&gt;%\n  as.matrix()\n\nmean_diff &lt;- mean_x - mean_y\nmean_diff\n\n     Sepal.Length_mean Sepal.Width_mean Petal.Length_mean Petal.Width_mean\n[1,]            -0.652           -0.204            -1.292             -0.7\n\n\n이제 두 그룹에 대한 공분산 행렬을 구하고 합동 분산 추정량을 구해보자.\n\n# 그룹별 4개의 변수에 대한 공분산 행렬을 List 형식으로 저장\ncov_tbl &lt;- df %&gt;%\n  group_by(Species) %&gt;%\n  summarise(cov = list(cov(across(where(is.numeric)))), .groups = \"drop\")\ncov_tbl\n\n# A tibble: 2 × 2\n  Species    cov          \n  &lt;fct&gt;      &lt;list&gt;       \n1 versicolor &lt;dbl [4 × 4]&gt;\n2 virginica  &lt;dbl [4 × 4]&gt;\n\n# versicolor 종의 공분산 행렬 꺼내기 (마지막에 .[[1]] 은 앞의 개체에서 첫 번째 요소를 추출하는 명령)\ncov_x &lt;- cov_tbl %&gt;% filter(Species == \"versicolor\") %&gt;% pull(cov) %&gt;% .[[1]]\ncov_x\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length   0.26643265  0.08518367   0.18289796  0.05577959\nSepal.Width    0.08518367  0.09846939   0.08265306  0.04120408\nPetal.Length   0.18289796  0.08265306   0.22081633  0.07310204\nPetal.Width    0.05577959  0.04120408   0.07310204  0.03910612\n\n# virginica 종의 공분산 행렬 꺼내기\ncov_y &lt;- cov_tbl %&gt;% filter(Species == \"virginica\") %&gt;% pull(cov) %&gt;% .[[1]]\ncov_y\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length   0.40434286  0.09376327   0.30328980  0.04909388\nSepal.Width    0.09376327  0.10400408   0.07137959  0.04762857\nPetal.Length   0.30328980  0.07137959   0.30458776  0.04882449\nPetal.Width    0.04909388  0.04762857   0.04882449  0.07543265\n\n# 합동 공분산 행렬\nSp &lt;- ((n1-1) * cov_x  + (n2-1) * cov_y  ) / (n1 + n2 - 2)\nSp\n\n             Sepal.Length Sepal.Width Petal.Length Petal.Width\nSepal.Length   0.33538776  0.08947347   0.24309388  0.05243673\nSepal.Width    0.08947347  0.10123673   0.07701633  0.04441633\nPetal.Length   0.24309388  0.07701633   0.26270204  0.06096327\nPetal.Width    0.05243673  0.04441633   0.06096327  0.05726939\n\n\n이제 다음과 같이 위에서 구한 표본 통계량을 이용하여 Hotelling \\(T^2\\) 을 다음과 같이 구할 수 있다.\n\n# 평균벡터와 공분산 행렬의 차원 확인 \ndim(mean_diff); dim(Sp)\n\n[1] 1 4\n\n\n[1] 4 4\n\n# Hotelling T^2 통계량 계산\nT2 &lt;- (n1*n2/(n1+n2)) * mean_diff %*% solve(Sp) %*% t(mean_diff)\nT2\n\n         [,1]\n[1,] 355.4721\n\n\n이제 기각역을 다음과 같이 구하고 위의 호텔링의 \\(T^2\\) 통계량과 비교해보자\n\n# 유의수준\nalpha &lt;- 0.05\n# F-분포의 임계값\nF_crit &lt;- qf(1-alpha, df1 = p, df2 = n1 + n2 - p - 1)\nF_crit\n\n[1] 2.467494\n\n\n호텔링의 \\(T^2\\) 통계량의 값 355.4721452 이 기각역 2.4674936 보다 크므로 귀무가설을 기각한다. 즉, 두 종 versicolor와 virginica의 평균벡터가 통계적으로 유의하게 다르다고 할 수 있다.\n위에서 직접구한 것과 동일한 결과를 주는 R 패키지 Hotelling의 hotelling.test() 함수를 사용하여 검정을 수행해보자. 이 함수는 등공분산 가정을 전제로 한다.\n\nlibrary(Hotelling)\nres &lt;- hotelling.test(Sepal.Length + Sepal.Width + Petal.Length + Petal.Width ~ Species, data = df, var.equal = TRUE)\nres\n\nTest stat:  355.47 \nNumerator df:  4 \nDenominator df:  95 \nP-value:  0",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>다변량 가설 검정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-cov.html",
    "href": "qmd/multivar-cov.html",
    "title": "4  공분산 행렬의 추정",
    "section": "",
    "text": "4.1 공분산 행렬의 정의\n공분산행렬은 다변량 분석에서 여러 변수들 간의 관계를 살펴볼 수 있는 가장 기본적이고 중요한 요소이다. 공분산행렬의 구조를 이해하고 적절히 추정하는 것은 다변량 데이터 분석에서 매우 중요하다. 본 장에서는 공분산 행렬의 다양한 구조적 형태와 이를 추정하는 방법들을 간단히 소개한다.\n먼저 \\(p\\)-차원 확률벡터 \\(\\pmb X\\) 가 다변량 정규분포를 따른다고 가정하자.\n\\[\n\\pmb X  =\n\\begin{bmatrix}\nX_1 \\\\\nX_2 \\\\\n\\vdots \\\\\nX_p\n\\end{bmatrix}\n\\sim N_p({\\pmb \\mu}, {\\pmb \\Sigma})\n\\]\n공분산 행렬 \\(\\Sigma\\) 는 다음과 같이 정의되며\n\\[\n\\pmb \\Sigma = \\mathrm{Var}(\\pmb{X}) = \\pmb{E}\\big[(\\pmb{X}- \\pmb \\mu)(\\pmb{X}-\\pmb  \\mu)^\\top\\big], \\quad\n\\pmb{X} \\in \\RR^p\n\\] 다음과 같은 성질을 가지고있다.\n\\[\n\\pmb{a}^{\\top} {\\pmb \\Sigma} \\pmb{a} \\ge 0 \\quad \\text{ for all } \\pmb{a} \\in \\RR^p\\]\n이제 다변량 정규분포를 따르는 예제 데이터를 생성하고, 표본 공분산 행렬을 계산해 보자. 평균는 모두 0 이고 다음과 같은 공분산행렬을 가지는 6차원 다변량 정규분포를 고려한다. 다변량 정규분포에서 100개의 표본을 임의로 추출한 다음 표본 공분산 행렬을 구해보자.\n\\[\n\\Sigma = \\begin{bmatrix}\n  1.0 &  0.4 &  0.2 &  0.5 &  0.1 & -0.2 \\\\\n  0.4 &  1.0 &  0.3 &  0.4 & -0.3 &  0.01 \\\\\n  0.2 &  0.3 &  1.0 &  0.3 &  0.2 & -0.1 \\\\\n  0.5 &  0.4 &  0.3 &  1.0 &  0.4 & -0.2 \\\\\n  0.1 & -0.3 &  0.2 &  0.4 &  1.0 &  0.2 \\\\\n-0.2 &  0.01 & -0.1 & -0.2 &  0.2 &  1.0\n\\end{bmatrix}\n\\]\n# 예제 데이터 (다변량 정규)\n\n# 공분산 행렬\nSigma_true &lt;- matrix(c(\n  1.0,  0.4,  0.2,  0.5,  0.1, -0.2,\n  0.4,  1.0,  0.3,  0.4, -0.3,  0.01,\n  0.2,  0.3,  1.0,  0.3,  0.2, -0.1,\n  0.5,  0.4,  0.3,  1.0,  0.4, -0.2,\n  0.1, -0.3,  0.2,  0.4,  1.0,  0.2,\n -0.2,  0.01, -0.1, -0.2,  0.2,  1.0\n), 6, 6, byrow = TRUE)\n\nSigma_true\n\n     [,1]  [,2] [,3] [,4] [,5]  [,6]\n[1,]  1.0  0.40  0.2  0.5  0.1 -0.20\n[2,]  0.4  1.00  0.3  0.4 -0.3  0.01\n[3,]  0.2  0.30  1.0  0.3  0.2 -0.10\n[4,]  0.5  0.40  0.3  1.0  0.4 -0.20\n[5,]  0.1 -0.30  0.2  0.4  1.0  0.20\n[6,] -0.2  0.01 -0.1 -0.2  0.2  1.00\n\n# 고유값 확인- 공분산행렬의 양반정치 점검\neigen(Sigma_true)$values  \n\n[1] 2.1507035 1.3633588 1.0108471 0.8176237 0.4860156 0.1714512\n\n# 다변량 정규분포에서 표본 생성\nset.seed(123) # 재현 가능성\nX &lt;- rmvnorm(n = 100, mean = c(0, 0, 0, 0, 0, 0), sigma = Sigma_true)\ncolnames(X) &lt;- c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\", \"x6\")\n\n# 표본의 일부 보기\nhead(X)\n\n              x1           x2         x3          x4         x5         x6\n[1,] -0.60697291 -0.016012988  1.3739779 -0.09555296  0.5483513  1.6489336\n[2,]  0.06807651 -1.514672553 -0.7643606 -0.39888978  1.2909460  0.4933002\n[3,]  0.98823956  0.285412440 -0.1300729  2.00665652  0.5701723 -2.0653381\n[4,]  0.46989680 -0.333468735 -1.1591075 -0.42188577 -1.0883766 -0.8543093\n[5,] -0.99065257 -1.222874588  0.3448429 -0.68099634 -0.4556374  1.0022332\n[6,]  0.58628469 -0.005235656  1.0113511  1.05145508  1.2414359  0.5797083\n\n# 표본 공분산 행렬\nS_hat &lt;- cov(X)\nS_hat\n\n            x1          x2         x3         x4          x5          x6\nx1  0.88057500  0.33490828  0.1872037  0.3207651 -0.05887987 -0.32665921\nx2  0.33490828  0.88314376  0.3453332  0.2363243 -0.37813166 -0.06704301\nx3  0.18720366  0.34533319  1.0006850  0.1587787  0.10083233 -0.01456920\nx4  0.32076508  0.23632432  0.1587787  0.8100167  0.28207315 -0.44437452\nx5 -0.05887987 -0.37813166  0.1008323  0.2820731  0.82579538  0.04660305\nx6 -0.32665921 -0.06704301 -0.0145692 -0.4443745  0.04660305  1.06484897\n\n# 추정량과 실제 공분산 행렬 비교: 각 분산과 공분산의 상대적인 오차(%)\nround(100 * (S_hat - Sigma_true) / (Sigma_true), 2)\n\n        x1      x2     x3     x4      x5      x6\nx1  -11.94  -16.27  -6.40 -35.85 -158.88   63.33\nx2  -16.27  -11.69  15.11 -40.92   26.04 -770.43\nx3   -6.40   15.11   0.07 -47.07  -49.58  -85.43\nx4  -35.85  -40.92 -47.07 -19.00  -29.48  122.19\nx5 -158.88   26.04 -49.58 -29.48  -17.42  -76.70\nx6   63.33 -770.43 -85.43 122.19  -76.70    6.48",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>공분산 행렬의 추정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-cov.html#공분산-행렬의-정의",
    "href": "qmd/multivar-cov.html#공분산-행렬의-정의",
    "title": "4  공분산 행렬의 추정",
    "section": "",
    "text": "대각원소는 각 변수의 분산, 비대각원소는 변수 간의 공분산을 나타낸다.\n대칭 행렬(symmeric matrix): \\(\\pmb \\Sigma^\\top = \\pmb \\Sigma\\)\n양반정치 행렬(semi-positive matrix):\n\n\n\n양반정치를 확인하는 방법은 공분산 행렬의 고유값이 모두 0 보다 같거나 커야한다.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>공분산 행렬의 추정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-cov.html#공분산-행렬의-형태",
    "href": "qmd/multivar-cov.html#공분산-행렬의-형태",
    "title": "4  공분산 행렬의 추정",
    "section": "4.2 공분산 행렬의 형태",
    "text": "4.2 공분산 행렬의 형태\n\n일반형 공분산\n\np-차원 공분산 행렬의 일반적인 구조(general 또는 unstructured) 는 다음과 같으며 대칭 행렬이기 떄문에 모수(parameter)의 개수는 \\(p(p-1)/2\\) 개이다.\n\\[\n\\pmb \\Sigma =\n\\begin{bmatrix}\n\\sigma_{11} & \\sigma_{12} & \\cdots & \\sigma_{1p} \\\\\n\\sigma_{12} & \\sigma_{22} & \\cdots & \\sigma_{2p} \\\\\n\\vdots      & \\vdots      & \\ddots & \\vdots      \\\\\n\\sigma_{1p} & \\sigma_{2p} & \\cdots & \\sigma_{pp}\n\\end{bmatrix}\n\\tag{4.1}\\]\n\n독립과 등분산\n\n다변량 정규분포에서 모든 변수 \\(X_1, X_2, \\dots, X_p\\) 가 독립인 경우 공분산이 0인 것과 동일하기 떄문에 다음과 같은 대각행렬의 형태를 가지게 된다.\n\\[\n\\pmb \\Sigma =\n\\begin{bmatrix}\n\\sigma_1^2 & 0 & \\cdots & 0 \\\\\n0 & \\sigma_2^2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\sigma_p^2\n\\end{bmatrix}\n\\]\n이 경우 다음과 같이 각 확률변수가 독립적으로 분산이 다른 일변량 정규분포를 따른다고 할 수 있다.\n\\[\nX_i \\sim_{indep} N(\\mu_i, \\sigma_i^2), \\quad i=1,2,\\dots,p\n\\] 더 나아가 모든 변수의 분산이 동일한 경우(등분산)에는 다음과 같은 구형(spherical) 형태의 공분산 행렬을 가진다.\n\\[\n\\pmb \\Sigma =\n\\begin{bmatrix}\n\\sigma^2 & 0 & \\cdots & 0 \\\\\n0 & \\sigma^2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & \\cdots & \\sigma^2\n\\end{bmatrix}\n=\n\\sigma^2 {\\pmb I}_p\n\\]\n\n균등 상관 구조\n\n특별한 구조를 고려하는 경우, 공분산 행렬의 형태로 가장 자주 사용되는 구조가 균등 상관 구조(Compound Symmetry, CS) 이다. 이 형태는 분산이 모두 동일하고 공분산도 모두 동일한 형태이며 분산과 공분산은 다르게 설정된다. 즉 모든 변수의 분산이 \\(\\sigma^2\\) 이고 모든 변수 쌍들의 공분산이 \\(\\rho\\sigma^2\\) 인 경우이다. 따라서 \\(\\rho\\) 는 상관 계수이다. 따라서 모든 변수의 상관계수도 동일한 형태를 가지는 구조이다.\n\\[\ncor(X_i, X_j) = \\rho \\quad \\text{ for all } i,j\n\\]\n\\[\n\\pmb \\Sigma_{\\text{CS}} =\n\\begin{bmatrix}\n\\sigma^2 & \\rho\\sigma^2 & \\cdots & \\rho\\sigma^2 \\\\\n\\rho\\sigma^2 & \\sigma^2 & \\cdots & \\rho\\sigma^2 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\rho\\sigma^2 & \\rho\\sigma^2 & \\cdots & \\sigma^2\n\\end{bmatrix}\n= \\sigma^2 \\big [ (1-\\rho) \\pmb  I_p + \\rho \\pmb  J_p \\big ]\n\\tag{4.2}\\]\n위의 식에서 \\(\\pmb J_p\\) 는 모든 원소가 1인 \\(p\\times p\\) 행렬이다.\n\n4.2.1 AR(1) 구조\n공분산 행렬의 또 다른 구조적 형태로는 AR(1) 구조가 있다. 이 형태는 시계열 자료에서 자주 사용되는 구조로서, 인접한 변수들 간의 상관관계가 멀어질수록 지수적으로 감소하는 특징을 가진다.\n\\[\ncor(X_i, X_j) =  \\rho^{|i-j|}\n\\]\nAR(1) 구조의 공분산 행렬은 다음과 같은 형태를 가진다.\n\\[\n\\pmb \\Sigma_{AR} =\n\\begin{bmatrix}\n\\sigma^2 & \\rho\\sigma^2 & \\rho^2\\sigma^2 & \\cdots & \\rho^{p-1}\\sigma^2 \\\\\n\\rho\\sigma^2 & \\sigma^2 & \\rho\\sigma^2 & \\cdots & \\rho^{p-2}\\sigma^2 \\\\\n\\rho^2\\sigma^2 & \\rho\\sigma^2 & \\sigma^2 & \\cdots & \\rho^{p-3}\\sigma^2 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\rho^{p-1}\\sigma^2 & \\rho^{p-2}\\sigma^2 & \\rho^{p-3}\\sigma^2 & \\cdots & \\sigma^2\n\\end{bmatrix}\n\\]\n따라서 AR(1) 구조를 가진 다변량 확률 벡터의 상관 계수 행렬은 다음과 같이 나타낼 수 있다.\n\\[\n\\pmb R =\n\\begin{bmatrix}\n1 & \\rho & \\rho^2 & \\cdots & \\rho^{p-1} \\\\\n\\rho & 1 & \\rho & \\cdots & \\rho^{p-2} \\\\\n\\rho^2 & \\rho & 1 & \\cdots & \\rho^{p-3} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n\\rho^{p-1} & \\rho^{p-2} & \\rho^{p-3} & \\cdots & 1\n\\end{bmatrix}\n\\]\n\n\n4.2.2 블록 대각 구조\n공분산 행렬의 또 다른 구조적 형태로는 블록 대각(Block Diagonal) 구조가 있다. 이 형태는 변수들이 여러 개의 그룹으로 나누어져 있고, 각 그룹 내에서는 변수들 간에 상관관계가 존재하지만, 그룹 간에는 상관관계가 없는 경우에 적합하다. 블록 대각 구조의 공분산 행렬은 다음과 같은 형태를 가진다.\n\\[\n\\pmb \\Sigma =\n\\begin{bmatrix}\n\\pmb  \\Sigma_{1} & \\pmb  0  & \\pmb  0\\\\\n\\pmb  0 & \\pmb  \\Sigma_{2} & \\pmb  0 \\\\\n\\pmb  0 & \\pmb  0 & \\pmb  \\Sigma_{3}\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>공분산 행렬의 추정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-cov.html#공분산의-추정",
    "href": "qmd/multivar-cov.html#공분산의-추정",
    "title": "4  공분산 행렬의 추정",
    "section": "4.3 공분산의 추정",
    "text": "4.3 공분산의 추정\n\n4.3.1 표본 공분산 행렬\n만약 \\(n\\) 개의 표본 \\(\\pmb X_1, \\pmb X_2, \\dots, \\pmb X_n\\) 이 관측되었다고 하자.\n만약 분포의 가정에서 공분산이 제약이 없는 일반적인 형태 식 4.1 라고 한다면 다음과 같은 표본 공분산 행렬을 이용하여 추정한다. 이 추정량은 불편추정량(unbiased estimator)이고 동시에 \\(n\\) 이 충분히 크면 최대가능도 추정량과 동일하다고 볼 수 있다.\n\\[\n\\hat{\\Sigma} = \\frac{1}{n-1}\\sum_{i=1}^n (\\pmb{X}_i-\\bar{\\pmb{X}})(\\pmb{X}_i-\\bar{\\pmb{X}})^\\top\n\\tag{4.3}\\]\n특별한 구조를 가진 공분산 행렬은 최대가능도 추정을 이용하여 추정할 수 있다.\n\n\n4.3.2 예제: 반복측정자료\n이 장에서는 의학통계에 자주 사용되는 반복측정자료 형태의 다변량 확률벡터에 대하여 균등 상관 구조 형태의 공분산 행렬을 추정하는 예제에 대해서 살펴 보자.\n확률변수 \\(X_i\\) 는 \\(i\\) 시점에서 순서대로 5번 관측한 자료이며 한 명의 개체가 각 시점에서 반응값을 측정한다고 하자. 따라서 반복으로 측정한 확률 변수 \\(X_1, X_2, \\dots, X_5\\) 는 독립이 아니다.\n이제 확률 벡터 \\(\\pmb X = (X_1, X_2, \\dots, X_5)^t\\) 가 다변량 정규분포를 따른다고 가정하자. 5-차원의 다변량 정규 확률 벡터를 고려하고 각 변수의 평균은 시간을 나타내는 시점 (\\(i\\))에 비례하게 다음과 같이 정의한다.\n\\[\n\\mu_i = E(X_i) = 0.5 + 0.1 (i - 1)\n\\]\n공분산 행렬은 식 4.2 의 균등 상관 구조를 가지며 분산은 모두 1 이고 상관계수는 0.6으로 가정한다. 표본의 개수는 100 개이다.\n먼저 주어진 평균벡터와 공분산 행렬에 대하여 분포를 정의하고 가상의 자료를 임의로 추출하는 R 코드를 고려한다.\n\nset.seed(121)\nn  &lt;- 100          # 표본 수\np  &lt;- 5            # 확률 벡터의 차원 \n\n# 각 개체의 id 와 시간 변수 생성\nid &lt;- factor(rep(1:n, each = p))\ntime &lt;- rep(1:p, times = n)\nmu &lt;- 0.5 + 0.1 * (rep(1:p, times = 1) - 1)  # 평균 벡터\n\n#   p- 차원 CS 공분산을 만드는 함수 \nmake_Sigma_CS &lt;- function(p, sigma2 = 1, rho = 0.3) {\n  if (rho &lt;= -1/(p - 1) || rho &gt;= 1) {\n    stop(\"rho must be in (-1/(p-1), 1) to ensure positive definiteness.\")\n  }\n  J &lt;- matrix(1, p, p)         # 모든 원소가 1인 행렬\n  Sigma &lt;- sigma2 * ((1 - rho) * diag(p) + rho * J)\n  return(Sigma)\n}\n\n# 균등 상관 구조의 공분산 행렬\nSigma_true &lt;- make_Sigma_CS(p, sigma2 = 1, rho = 0.6)\nSigma_true\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  1.0  0.6  0.6  0.6  0.6\n[2,]  0.6  1.0  0.6  0.6  0.6\n[3,]  0.6  0.6  1.0  0.6  0.6\n[4,]  0.6  0.6  0.6  1.0  0.6\n[5,]  0.6  0.6  0.6  0.6  1.0\n\n\n이제 100 개의 표본을 다변량 정규분포에서 임의로 추출하고 wide 형식의 자료로 변환해 보자.\n\nXmat &lt;- rmvnorm(n = n, mean = mu, sigma = Sigma_true) # 다변량 표본 추출\ncolnames(Xmat) &lt;- paste0(\"X\", 1:p)\n\ndf_wide &lt;- as.data.frame(Xmat) # wide 형식의 자료\nhead(df_wide)\n\n          X1          X2         X3          X4          X5\n1  0.1412804  0.47132670  0.5836000  0.55150916  0.25141129\n2  1.9259813  1.19236353  1.0678925  0.50890233  1.88213477\n3  1.4160815  0.08403608  0.4753524  0.47093252  1.27335173\n4  1.1549582 -0.30705522  1.4909395  0.08919076  1.23971146\n5  1.2631167  1.31918169  1.2023846  1.90247109  1.83556681\n6 -0.6336252  0.47159709 -0.6432958 -0.37359215 -0.06331619\n\n\n추출된 표본을 이용하여 식 4.3 에 주어진 표본 공분산 행렬을 계산해 보자. 표본 공분산 행렬은 제약조건이 없는 형태로 나타나기 때문에 모든 분산과 공분산이 각각 다르게 추정된다.\n\ncov(df_wide)\n\n          X1        X2        X3        X4        X5\nX1 0.7180133 0.4216849 0.3886342 0.3553769 0.4661159\nX2 0.4216849 0.8704348 0.4896497 0.4478777 0.4441199\nX3 0.3886342 0.4896497 0.8766630 0.4369850 0.5013652\nX4 0.3553769 0.4478777 0.4369850 0.7887407 0.4043893\nX5 0.4661159 0.4441199 0.5013652 0.4043893 0.9236021\n\n\n이제 균등 상관 구조를 가지는 공분산을 추정할 수 있는 방법을 알아보자. 먼저 자료는 측정 시간을 변수로 하는 긴 형식의 자료로 생성한다.\n\n# pivot_longer 함수를 이용하여 긴 형식의 자료를 생성  \ndf_long &lt;- df_wide %&gt;%\n  mutate(id = factor(1:n)) %&gt;%\n  pivot_longer(cols = starts_with(\"X\"), \n               names_to = \"time\", \n               values_to = \"y\",\n               names_prefix = \"X\") %&gt;%\n  mutate(time = as.integer(time))\nhead(df_long, 10)\n\n# A tibble: 10 × 3\n   id     time     y\n   &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;\n 1 1         1 0.141\n 2 1         2 0.471\n 3 1         3 0.584\n 4 1         4 0.552\n 5 1         5 0.251\n 6 2         1 1.93 \n 7 2         2 1.19 \n 8 2         3 1.07 \n 9 2         4 0.509\n10 2         5 1.88 \n\n\n공분산 추정을 위하여 nlme 패키지에 있는 다변량 확률변수의 회귀식을 추정하는 함수 nlme 를 사용하여고 하며, 균등 상관 구조를 가지는 공분산을 가정한다.\n다음 추정된 다변량 회귀모형의 결과를 보면 식 4.2 의 균등 상관 구조에서 분산 \\(\\sigma\\) 의 추정값은 \\(0.8362 = (0.9144)^2\\), 상관계수 \\(\\rho\\) 의 추정값은 \\(0.52078\\) 로 나타난다. 참고로 아래 결과에서 rho 는 공통 상관계수의 추정값,Residual standard error 는 표준편차 추정값이다.\n\nfit_gls_cs &lt;- gls(y ~ time, data = df_long,\n                  correlation = corCompSymm(form = ~ 1 | id))\n\nsummary(fit_gls_cs) \n\nGeneralized least squares fit by REML\n  Model: y ~ time \n  Data: df_long \n       AIC      BIC    logLik\n  1163.245 1180.088 -577.6226\n\nCorrelation Structure: Compound symmetry\n Formula: ~1 | id \n Parameter estimate(s):\n      Rho \n0.5207752 \n\nCoefficients:\n                Value  Std.Error  t-value p-value\n(Intercept) 0.3750164 0.09360729 4.006274   1e-04\ntime        0.0817480 0.02001772 4.083779   1e-04\n\n Correlation: \n     (Intr)\ntime -0.642\n\nStandardized residuals:\n        Min          Q1         Med          Q3         Max \n-2.76158379 -0.71458351  0.04453439  0.76834584  3.26193595 \n\nResidual standard error: 0.9144187 \nDegrees of freedom: 500 total; 498 residual\n\n# rho 는 공통 상관계수, Residual standard error 는 표준편차 추정값\n\n위에서 주어진 결과를 가지고 공분산 행렬의 추정값을 다음과 같이 구할 수 있다.\n\ngetVarCov(fit_gls_cs) \n\nMarginal variance covariance matrix\n        [,1]    [,2]    [,3]    [,4]    [,5]\n[1,] 0.83616 0.43545 0.43545 0.43545 0.43545\n[2,] 0.43545 0.83616 0.43545 0.43545 0.43545\n[3,] 0.43545 0.43545 0.83616 0.43545 0.43545\n[4,] 0.43545 0.43545 0.43545 0.83616 0.43545\n[5,] 0.43545 0.43545 0.43545 0.43545 0.83616\n  Standard Deviations: 0.91442 0.91442 0.91442 0.91442 0.91442",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>공분산 행렬의 추정</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-discrim.html",
    "href": "qmd/multivar-discrim.html",
    "title": "5  판별분석",
    "section": "",
    "text": "5.1 분포와 판별규칙\n의사결정은 주어진 유한개의 선택들 중에서 하나를 고르는 것이다. 예를 들어 은행에서 대출 신청자에게 돈을 빌려줄지 말지, 이동 시에 택시를 탈지, 버스를 탈지 또는 지하철을 탈지 결정해야 한다. 인간은 의사결정을 할 때 어느 정도의 자신만의 규칙에 따라 움직이며(아닌 경우도 많지만..) 여러 번의 시행 착오 등을 거쳐서 좋은 선택을 위해 규칙을 바꾸기도 한다. 또한 유한개의 선택들은 대체로 두 가지의 선택이 있으며 둘 중 하나를 선택하는 경우가 많다.\n예를 들어, 신용평가에서 은행은 과거 경험을 통해 두 부류의 고객이 있음을 알고 있다. 즉, 대출을 아무 문제 없이 상환하는 안전 고객과 상환에 어려움을 겪은 위험 고객이다. 새로운 고객이 대출을 신청할 때, 은행은 대출을 해줄지 말지를 결정해야 한다. 은행의 과거 기록은 두 부류의 고객에 대한 다수의 특성값들를 제공하며, 여기에는 나이, 급여, 혼인 여부, 대출 금액 등과 같은 다양한 정보가 포함된다. 새로운 고객은 새로운 특성값을 가지고 있으며 판별 규칙(Discrimination rule)은 이 새로운 고객을 두 집단 중 하나로 분류해야 하는 규칙을 말하는 것이다.\n판별분석(Discriminant analysis)은 이러한 의사결정에서 통계적 분포과 방법을 사용하여 자료에 기반한 규칙을 정하는 방법이다. 기본적으로 전체 집단(모집단)이 두 개 이상의 집단들로 나누어져 있다고 생각하고 그 집단들에 대한 확률적 가정(분포 가정)을 고려한다. 같은 집단에 속하는 개체들은 유사하며 다른 집단에 속한 개체들은 그 특성이 다르다고 가정하고 이러한 집단의 특성을 확률적 분포로 나타낸다.\n예를 들어 이동시 자가용을 타는 사람들과 대중교통을 타는 사람들은 소득의 분포가 다르다고 가정할 수 있다. 이러한 가정 아래 새로운 개체를 어느 집단에 배정하는지에 대한 규칙을 자료를 이용하여 정하는 방법이 판별분석이며 다양한 분류방법(classification)의 출발점이다. 유의할 점은 규칙을 정할 때 어떤 규칙이 좋은 것인지에 대한 기준을 생각해야 한다. 동일한 상황에서 두 가지 규칙을 비교할 수 있어야 더 나은 의사결정을 할 수 있다.\n판별분석에서는 다음과 같은 개념들을 생각헤야 한다.\n이 장에서는 두 개의 집단(population) \\(P_1\\) 과 \\(P_2\\) 을 고려한다. 예를 들어 은행에서는 전체 고객을 안전 고객과 위험 고객, 두 집단으로 나눌 수 있다.\n각 집단에 속하는 개체들의 특성(확률벡터) \\(\\pmb X\\) 은 속하는 집단에 따라서 각각 분포 \\(F_i(\\pmb x)\\), \\(i=1,2\\) 를 따른다고 가정한다. 또한 \\(f_i(\\pmb x)\\)를 분포 \\(F_i\\)의 확률밀도함수라고 하자.\n판별 규칙(discrimination rule) 은 새로운 개체의 특성 \\(\\pmb X = \\pmb x\\) 가 주어졌을 때 이 개체가 어느 집단에 속하는지 결정하는 방법이다. 이러한 규칙은 개체의 특성삾이 가질 수 있는 전체 공간(표본공간)을 겹치지 않는 두 집합 \\(R_1\\) 과 \\(R_2\\) 로 나누고 관측된 값이 \\(R_1\\) 에 속하면 새로운 개체를 \\(P_1\\) 에 베정하고, 반대로 \\(R_2\\) 에 속하면 \\(P_2\\)에 배정하는 것으로 주어진다.\n\\[\n\\text { where }  R_1 \\cup R_2 = \\RR^p, \\quad R_1 \\cap R_2 = \\emptyset\n\\tag{5.1}\\]\n즉, \\(R_1\\) 과 \\(R_2\\) 는 전체 공간을 겹치지 않게 나누는 두 집합이다. 판별 규칙은 다음과 같이 쓸 수 있다. \\[\n\\pmb x \\in R_1 \\Rightarrow \\text{개체를 } P_1 \\text{에 배정} \\\\\n\\pmb x \\in R_2 \\Rightarrow \\text{개체를 } P_2 \\text{에 배정}\n\\tag{5.2}\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>판별분석</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-discrim.html#분포와-판별규칙",
    "href": "qmd/multivar-discrim.html#분포와-판별규칙",
    "title": "5  판별분석",
    "section": "",
    "text": "5.1.1 판별 오류와 비용\n이제 \\(i\\) 집단에 속한 개체가 주어진 판별 규칙에 따라서 \\(j\\) 집단에 배정될 사건과 확률을 생각헤 보자. 먼저 \\(i\\) 집단에 속한 개체가 \\(j\\) 집단에 배정될 사건을 \\(A(j|i) \\equiv A_{ji}\\) 라고 정의한다. 따라서 각 개체가 자신이 속한 집단에 배정된 사건, \\(A_{11}\\) 과 \\(A_{22}\\) 가 발생하면 판별규칙이 잘 적용된 경우이다. 반대로 개체가 자신이 속하지 않은 다른 집단에 배정된 사건, \\(A_{12}\\) 과 \\(A_{21}\\) 가 발생하면 오류가 발생한 경우이며 이러한 경우 오류에 의한 비용 \\(c_{12}\\), \\(c_{21}\\) 이 발생한다.\n예를 들어 은행에서 대출 신청자가 우량 고객 \\(P_1\\) 에 속하는데 불량 고객 \\(P_2\\) 로 잘못 판별되어 대출을 거절하는 경우, 은행은 대출 이익을 얻지 못하는 손실 \\(c_{21}\\) 이 발생한다. 반대로 불량 고객 \\(P_2\\) 가 우량 고객 \\(P_1\\) 으로 잘못 판별되어 대출을 해주는 경우, 은행은 대출금을 상환받지 못하는 더 큰 손실 \\(c_{12}\\) 이 발생한다. 따라서 두 가지 오류에 대한 비용은 일반적으로 다르며, 이러한 비용을 고려하여 판별 규칙을 정하는 것이 중요하다.\n\n\n5.1.2 최대가능도 규칙\n이제 위에서 정의한 사건과 비용을 이용하여 판별 분석에서 다루는 중요한 확률을 생각해보자. 먼저 첫 집단 \\(P_1\\) 에 속한 개체가 주어진 판별 규칙에 따라서 두 번째 집단 \\(P_2\\) 에 배정될 사건확률은 다음과 같다.\n\\[\np_{21} \\equiv P(A_{21}) = \\int_{R_2} f_1(\\pmb x) d\\pmb x\n\\tag{5.3}\\]\n마찬가지로 \\(P_2\\) 에 속한 개체가 \\(P_1\\) 에 배정될 확률은 다음과 같다.\n\\[\np_{12} \\equiv P(A_{12}) = \\int_{R_1} f_2(\\pmb x) d\\pmb x\n\\tag{5.4}\\]\n위에서 정의한 두 확률 \\(p_{12}\\) 와 \\(p_{21}\\) 은 판별에서 오류가 발생한 확률이다.\n판별 규칙을 만드는 것은 식 5.1 과 식 5.2 에서 정의한 두 집합 \\(R_1\\) 과 \\(R_2\\) 를 정하는 것이다. 따라서 잘못된 분류를 범할 확률 식 5.3 과 식 5.4 은 판별 규칙에 따라서 달라진다. 즉, \\(R_1\\) 과 \\(R_2\\) 를 다르게 정하면 오류 확률도 달라진다.\n판별 규칙은 당연히 두 오류의 확률을 가장 작게 만드는 방향으로 정해져야 한다. 이제 앞에서 정의한 두 그룹의 분포를 이용하여 오류의 확률을 가장 작게 만드는 판별 규칙을 어떻게 정할 수 있는지 알아보자. 다음과 같이 두 오류를 범할 확률을 최소로 하는 판별 규칙을 찾으려 한다\n\\[\n\\min_{R_1, R_2} \\{ p_{12} + p_{21} \\} = \\min_{R_1, R_2} \\left [ \\int_{R_1} f_2(\\pmb x) d\\pmb x + \\int_{R_2} f_1(\\pmb x) d\\pmb x \\right ]\n\\tag{5.5}\\]\n위의 식은 두 오류 확률의 합을 최소로 하는 판별 규칙을 찾는 문제이다. 두 종류의 오류를 범할 확률의 합을 다시 살펴보면 다음과 같이 쓸 수 있다.\n\\[\n\\begin{aligned}\np_{12} + p_{21} & = \\int_{R_1} f_2(\\pmb x) d\\pmb x + \\int_{R_2} f_1(\\pmb x) d\\pmb x \\\\\n& = \\int_{R_1} f_2(\\pmb x) d\\pmb x + 1 - \\int_{R_1} f_1(\\pmb x) d\\pmb x \\\\\n& = 1 + \\int_{R_1} \\{ f_2(\\pmb x) - f_1(\\pmb x) \\} d\\pmb x\n\\end{aligned}\n\\tag{5.6}\\]\n참고로 위의 식은 전채 공간에서의 확률밀도함수의 적분이 1임을 이용하였다.\n\\[\n\\int_{R_1} f_1{\\pmb x} d \\pmb x + \\int_{R_2} f_1(\\pmb x) d\\pmb x = 1\n\\]\n이제 식 5.6 의 적분값을 최소로 하는 \\(R_1\\) 을 찾으면 된다. 이 적분값을 최소로 하기 위해서는 적분하는 영역 \\(R_1\\) 에서 적분하는 함수 \\(f_2(\\pmb x) - f_1(\\pmb x)\\) 의 값이 음수인 부분만 포함되도록 하면 된다. 즉, 다음과 같은 조건을 만족하는 \\(R_1\\) 을 찾으면 된다.\n\\[\nR_1 = \\{ \\pmb x | f_2(\\pmb x) - f_1(\\pmb x) &lt; 0 \\} = \\{ \\pmb x | f_1(\\pmb x) &gt; f_2(\\pmb x) \\}\n\\tag{5.7}\\]\n만약 \\(R_1\\) 을 식 5.7 과 같이 정하면 \\(R_2\\) 는 자동으로 다음과 같이 정해진다.\n\\[\nR_2 = \\{ \\pmb x | f_2(\\pmb x) \\ge f_1(\\pmb x) \\}\n\\tag{5.8}\\]\n위의 유도에서 판별 규칙을 만들 때 중요한 요인은 두 확률밀도함수의 비(ratio)이다. 두 확률밀도함수의 비가 1 보다 큰 값을 가지는 표본 \\(\\pmb x\\) 의 영역과 1 보다 작은 값을 가지는 표본 \\(\\pmb x\\) 의 영역이 각각 \\(R_1\\) 과 \\(R_2\\)가 되는 것이다.\n\\[  \\frac{f_1(\\pmb x)}{f_2(\\pmb x)} \\]\n앞에서 살펴보았듯이, 판별 함수를 만드는 가장 기본적인 방법은 최대 가능도 규칙(Maximum Likelihood Rule)이다. 이 방법은 새로운 개체의 특성 \\(\\pmb X = \\pmb x\\) 가 주어졌을 때, 각 집단에서 이 특성이 관측될 가능도(likelihood function)를 계산하여 더 큰 집단에 개체를 배정하는 방법이다. 즉, 다음과 같이 판별 규칙을 정의한다.\n\\[\n\\pmb x \\in R_1 \\text{ if } f_1(\\pmb x) &gt; f_2(\\pmb x), \\quad \\text{ and } \\quad \\pmb x \\in R_2 \\text{ if } f_1(\\pmb x) \\le f_2(\\pmb x)\n\\]\n\n\n5.1.3 베이지안 규칙\n만약 각 집단에 속할 사전 확률(prior probability)이 각각 \\(\\pi_1\\) , \\(\\pi_2\\) 로 주어졌다고 하자. 사전확률은 관측하는 확률벡터의 분포를 고려하기 전에, 어떤 개체가 각 집단에 속할 가능성을 확률을 나타낸 것이다.\n예를 들어 앞에서 생각한 예제에서 은행의 대출 신청자가 우량 고객 집단에 속할 가능성과 물량 고객 집단에 속할 가능성이 다를 수 있다. 대부분의 사람들이 대출을 계획대로 상환하였다면 임의의 고객이 우량 고객일 가능성이 불량 고객일 가능성보다 매우 크다고 할 수 있다. 이러한 사전 정보를 고려하여 판별 규칙을 정하는 임의의 고객이 우량 고객 집단 \\(P_1\\) 에 속할 사전 확률을 \\(\\pi_1\\) 이라고 하고 불량 고객 \\(P_2\\) 에 속할 사전 확률이 \\(\\pi_2\\) 라고 할 수 있는 것이다.\n\\[ \\pi_1  = P(\\text{고객} \\in  P_1), \\quad \\pi_2 = P(\\text{고객} \\in P_2), \\quad \\pi_1 + \\pi_2 =1 \\]\n사전확률을 고려하는 경우, 베이즈 판별 규칙은 다음과 같이 정의된다. 즉, 새로운 개체의 특성 \\(\\pmb X = \\pmb x\\) 가 주어졌을 때, 각 집단에서 이 특성이 관측될 가능도(likelihood function)에 사전 확률을 곱한 값을 계산하여 더 큰 집단에 개체를 배정하는 방법이다. 이 경우 베이즈 판별 규칙(Bayes Discrimination Rule)은 다음과 같이 정의된다.\n\\[\n\\pmb x \\in R_1 \\text{ if } \\pi_1 f_1(\\pmb x) &gt; \\pi_2 f_2(\\pmb x), \\quad \\text{ and } \\quad \\pmb x \\in R_2 \\text{ if } \\pi_1 f_1(\\pmb x) \\le \\pi_2 f_2(\\pmb x)\n\\]\n위의 규칙에서 가능도 함수와 사전 확률의 곱을 사후 확률(posterior probability)이라고 한다. 사후 확률은 관측된 표본의 값이 주어진 경우 개체가 집단에 속할 확률을 의미한다.\n\\[\nP (P_i | \\pmb X = \\pmb x) \\propto \\pi_i f_i(\\pmb x), \\quad i=1,2\n\\]\n\n\n5.1.4 최적 판별 규칙\n이제 판별에서 발생하는 오류에 대한 비용도 함께 고려할 수 있는 최적의 규칙을 고려해 보자. 앞 절에서 정의한 오류에 대한 비용 \\(c_{12}\\) 와 \\(c_{21}\\) 을 고려할 때 최적 판별 규칙은 다음에서 정의한 기대 오류비용 (Expected cost of misclassification; ECM) 을 최소로 하는 규칙이다.\n\\[\n\\text{ECM} = c_{12} p_{12} \\pi_2 + c_{21} p_{21} \\pi_1\n\\tag{5.9}\\]\n기대 오류비용(ECM)을 최소로 하는 판별 규칙을 유도하면 다음과 같은 최적 판별 규칙을 얻을 수 있다.\n\\[\nR_1 = \\left \\{ \\pmb x | \\frac{f_1(\\pmb x)}{f_2(\\pmb x)} &gt; \\left [ \\frac{c_{12}}{c_{21}} \\right ] \\left [ \\frac{\\pi_2}{\\pi_1} \\right ] \\right \\}, \\quad R_2 = \\left \\{ \\pmb x | \\frac{f_1(\\pmb x)}{f_2(\\pmb x)} \\le \\left [ \\frac{c_{12}}{c_{21}} \\right ] \\left [ \\frac{\\pi_2}{\\pi_1} \\right ] \\right \\}\n\\tag{5.10}\\]\n식 5.10 에서 알 수 있듯이, 최대가능도 규칙과 베이즈 판별 규칙은 기대 오류비용을 최소화하는 최적 규칙의 특별한 경우이다. 즉, 비용이 동일한 경우 \\(c_{12} = c_{21}\\) 에는 베이즈 판별 규칙과 동일하다. 또한 사전 확률도 동일한 경우 \\(\\pi_1 = \\pi_2\\) 에는 최대 가능도 판별 규칙과 동일하다.\n\n예제 5.1 (두 정규 분포의 판별 규칙) 두 집단 \\(P_1\\) 과 \\(P_2\\) 에 속한 개체들의 특성 \\(\\pmb X\\) 가 각각 다음과 같은 분산이 동일한 일변량 정규 분포를 따른다고 하자.\n\\[\nX | P_1 \\sim N( \\mu_1,  \\sigma^2), \\quad  X | P_2 \\sim N(\\mu_2, \\sigma^2), \\quad \\mu_1 &lt; \\mu_2\n\\] 이제 두 정규분포 확률밀도함수의 비, 최대가능도 함수의 비율을 고려해 보자.\n\\[\n\\frac{f_1(x)}{f_2(x)} =  \\exp \\left \\{ - \\left ( \\frac{(x - \\mu_1)^2}{2\\sigma^2} \\right ) - \\left ( - \\frac{(x - \\mu_2)^2}{2\\sigma^2} \\right ) \\right \\}\n\\]\n위의 식에서 두 정규분포의 비가 1 보다 큰 표본의 영역 \\(R_1\\) 을 구하면 다음과 같다.\n\\[\n\\begin{aligned}\n&   \\frac{f_1(x)}{ f_2(x)} &gt; 1 \\\\\n& \\Longleftrightarrow   -\\frac{1}{2\\sigma^2}(x-\\mu_1)^2  + \\frac{1}{2\\sigma^2}(x-\\mu_2)^2 &gt; \\log(1) \\\\\n& \\Longleftrightarrow   2x\\mu_1 -\\mu_1^2 -2x \\mu_2 + \\mu_2^2 &gt; 0 \\\\\n& \\Longleftrightarrow   2x(\\mu_1 - \\mu_2)   &gt; \\mu_1^2 - \\mu_2^2  \\\\\n& \\Longleftrightarrow   x &lt; \\frac{\\mu_1+\\mu_2}{2}\n\\end{aligned}\n\\]\n따라서 두 집단의 평균의 중간에 있는 값 \\((\\mu_1 + \\mu_2)/2\\) 보다 관측한 값 \\(x\\) 가 작으면 그룹 \\(P_1\\) 에 속한다고 결정한다.\n\\[\nR_1 = \\left \\{ x | x &lt; \\frac{\\mu_1 + \\mu_2}{2} \\right \\}, \\quad R_2 = \\left \\{ x | x \\ge \\frac{\\mu_1 + \\mu_2}{2} \\right \\}\n\\]\n\\(\\square\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>판별분석</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-discrim.html#다변량-정규분포와-판별-규칙",
    "href": "qmd/multivar-discrim.html#다변량-정규분포와-판별-규칙",
    "title": "5  판별분석",
    "section": "5.2 다변량 정규분포와 판별 규칙",
    "text": "5.2 다변량 정규분포와 판별 규칙\n앞 절에서는 개체의 특성을 나타내는 확률변수가 일변량 정규분포인 경우의 예제를 보았다. 일반적인 경우 개체의 특성을 나타내는 특성값은 두 개 이상인 경우가 흔하다. 따라서 이제는 개체의 특성이 여러 개의 확률변수, 즉 확률벡터로 구성되어 있다고 가정하자.\n\\(p\\)차원 확률벡터 \\(\\pmb X\\) 를 고려하며 분포는 다변량 정규분포를 가정한다. 정규분포의 가정은 강한 가정이지만 단순하고 다루기 쉬운 분포이며 실제로 사용하기 용이하다. (하지만 조심해서 가정을 검토해야함)\n두 개의 다변량정규분포를 따르는 두 집단 \\(P_1, P_2\\)으로 나누어져 있다고 가정하고 두 분포를 고려하자. 처음에는 문제를 쉽게 하기 위하여 평균은 다르고 공분산은 같다고 가정하자\n\\[\nP_1 : ~N_p (\\pmb \\mu_1, \\pmb \\Sigma) , \\quad  P_2 :~ N(\\pmb \\mu_2, \\pmb \\Sigma)   \\quad \\text{ where } \\pmb \\mu_1 \\ne \\pmb \\mu_2\n\\]\n참고로 다변량 정규 분포의 확률 밀도 함수는 다음과 같다.\n\\[\nf(\\pmb x) = (2 \\pi)^{-p/2} |\\pmb \\Sigma |^{-1/2} \\exp \\left [\n-\\frac{1}{2} (\\pmb x -\\pmb \\mu)^t \\pmb \\Sigma^{-1} (\\pmb x -\\pmb \\mu) \\right ]\n\\]\n식 5.9 에서 기대 오류비용 ECM 을 최소하는 판별규칙 식 5.10 과 같이 구할 수 있으며 이제 다변량 정규분포의 확률밀도함수를 식 5.10 에 넣고 판별함수를 유도해 보자.\n\\[\n\\begin{aligned}\n\\frac{f_1(\\pmb x)}{f_2(\\pmb x)} & =\n\\exp \\left [ -\\frac{1}{2} (\\pmb x -\\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb x -\\pmb \\mu_1) +\n\\frac{1}{2} (\\pmb x -\\pmb \\mu_2)^t \\pmb \\Sigma^{-1} (\\pmb x\n-\\pmb \\mu_2)\\right ] \\\\\n& = \\exp \\left [ (\\pmb \\mu_1-\\pmb \\mu_2)^t \\pmb \\Sigma^{-1} \\pmb x -\n\\frac{1}{2} \\pmb \\mu_1^t \\pmb \\Sigma^{-1} \\pmb \\mu_1\n+\\frac{1}{2} \\pmb \\mu_2^t \\pmb \\Sigma^{-1} \\pmb \\mu_2) \\right ]  \\\\\n&= \\exp \\left [ (\\pmb \\mu_1-\\pmb \\mu_2)^t \\pmb \\Sigma^{-1} \\pmb x -\n\\frac{1}{2} (\\pmb \\mu_1-\\pmb \\mu_2)^t \\pmb \\Sigma^{-1} (\\pmb \\mu_1+\\pmb \\mu_2) \\right ]\n\\end{aligned}\n\\]\n이제 ECM을 최소화하는 규칙은 개체의 특성이 \\(\\pmb x =\\pmb x_0\\) 로 주어진 경우 다음을 만족하면 \\(P_1\\)으로 분류한다.\n\\[\n(\\pmb \\mu_1-\\pmb \\mu_2)^t \\pmb \\Sigma^{-1} \\pmb x_0 -\n\\frac{1}{2} (\\pmb \\mu_1-\\pmb \\mu_2)^t \\pmb \\Sigma^{-1} (\\pmb \\mu_1+\\pmb \\mu_2)\n&gt; \\log \\left ( \\frac{c_{12}}{c_{21}} \\frac{\\pi_2}{\\pi_1} \\right )\n\\]\n실제로 \\(\\pmb \\mu_1\\), \\(\\pmb \\mu_2\\), \\(\\pmb \\Sigma\\)은 알 수 없기 때문에 표본 자료를 이용하여 추정을 한다.\n\\[ \\hat {\\pmb \\mu}_1 = \\bar {\\pmb x}_1 \\quad \\text{and} \\quad \\hat {\\pmb \\mu}_2 = \\bar {\\pmb x}_2  \\]\n\\[ \\hat {\\pmb \\Sigma} = \\pmb S_{p} = \\frac{(n_1-1) \\pmb S_1+(n_2-1)\n\\pmb S_2}{ n_1+n_2-2 } \\]\n여기서 \\(n_1\\), \\(n_2\\)는 표본에서 두 그룹에 대한 표본의 크기이며 \\(\\bar {\\pmb x}_1\\), \\(\\bar {\\pmb x}_2\\)는 각각의 표본평균 벡터이다. \\(\\pmb S_{p}\\)는 두 개의 그룹에서 구한 공분산 행렬의 추정치를 결합한 합동 공분산 추정량이다.\n위에서 구한 모수들의 추정치를 모집단으로 부터 구한 판별함수에 넣으면 다음과 같은 표본을 이용한 판별함수가 얻어진다.\n\\[\n(\\bar {\\pmb x}_1-\\bar {\\pmb x}_2)^t \\pmb S_{p}^{-1} \\pmb x_0 -\n\\frac{1}{2} (\\bar {\\pmb x}_1-\\bar {\\pmb x}_2)^t \\pmb S_{p}^{-1} (\\bar\n{\\pmb x}_1+\\bar {\\pmb x}_2) &gt;  \\log \\left ( \\frac{c(1|2)}{c(2|1)}\n\\frac{\\pi_2}{\\pi_1} \\right )\n\\tag{5.11}\\]\n위 식 5.11 의 표본 판별함수에서 아래와 같이 벡터 \\(\\pmb a\\)와 상수 \\(m\\)을 정의하면\n\\[\n\\begin{aligned}\n\\pmb a & =  \\pmb S_{p}^{-1} (\\bar {\\pmb x}_1-\\bar {\\pmb x}_2)   \\\\\nm &  = \\frac{1}{2} (\\bar {\\pmb x}_1-\\bar {\\pmb x}_2)^t\n\\pmb S_{p}^{-1} (\\bar {\\pmb x}_1+\\bar {\\pmb x}_2) = \\frac{1}{2}(\\pmb a^t\n\\bar {\\pmb x}_1 + \\pmb a^t \\bar {\\pmb x}_2)\n\\end{aligned}\n\\tag{5.12}\\]\nECM을 최소화하는 판별 규칙은 다음과 같이 특성값 \\(\\pmb x_0\\)의 선형함수로 나타낼 수 있다.\n\\[\n\\pmb a^t \\pmb x_0 &gt;  m + \\log \\left ( \\frac{c(1|2)}{c(2|1)} \\frac{\\pi_2}{\\pi_1} \\right )\n\\tag{5.13}\\]\n만약 비용이 같고 (\\(c_{12}=c_{21}\\)) 두 집단에 대한 사전확률이 같다면 (\\(\\pi_1=\\pi_2\\)) 판별함수는 다음과 같이 간단하게 나타낼 수 있다.\n\\[  \n\\pmb a^t \\pmb x_0     &gt; m\n\\tag{5.14}\\]\n마지막으로 두 모집단의 공분산이 다를 경우는 판별함수가 확률벡터 \\(\\pmb x\\)의 선형함수로 나타나지 않는다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>판별분석</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-discrim.html#fisher의-선형-판별함수",
    "href": "qmd/multivar-discrim.html#fisher의-선형-판별함수",
    "title": "5  판별분석",
    "section": "5.3 Fisher의 선형 판별함수",
    "text": "5.3 Fisher의 선형 판별함수\nFisher(1938)는 위에서 다룬 ECM을 최소화하는 판별함수를 유도하는 방법과 완전히 다른 규칙을 사용하여 ECM을 최소화하는 방법과 동일한 결과를 유도하였다.\nFisher는 다변량 확률벡터 \\(\\pmb x\\)를 일변량 변수 \\(y\\) 로 선형변환하여 차원을 축소하는 방법을 고려하였다. 차원을 축소할 때 축소된 차원의 특성값 \\(y\\)가 두 집단을 최대로 구별되게 하는 선형변환을 구하는 문제를 생각하였다. Fisher의 방법은 특성값 벡터 \\(\\pmb x\\)에 확률적 분포가정을 고려하지 않는다.\n특성값 벡터 \\(\\pmb x_1\\)을 집단 \\(P_1\\)의 특성값이라고 하고 \\(\\pmb x_2\\)을 집단 \\(P_2\\)의 특성벡터라고 하자. 이제 특성값 벡터 \\(\\pmb x_1\\)과 \\(\\pmb x_2\\)에 동시에 적용하는 선형변환 벡터를 \\(\\pmb a\\)라고 하고 각 집단의 일변량 특성값 \\(y_1\\)과 $ y_2$를 다음과 같이 정의하자.\n\\[\ny_1 = \\pmb a^t \\pmb x_1 \\quad \\text{and} \\quad y_2 = \\pmb a^t \\pmb x_2\n\\] 이제 두 집단에서 각각 \\(n_1\\), \\(n_2\\) 개의 표본을 독립적으로 추출하였다거 가정하자.\n\\[\ny_{11}, y_{12}, \\dots, y_{1 n_1} \\sim_{ind} P_1 \\quad \\text{and} \\quad y_{21}, y_{22}, \\dots, y_{2 n_2} \\sim_{ind} P_2\n\\] 각 집단의 평균벡터는 다음과 같이 일변량 평균으로 변환된다. \\[\n\\bar y_1 = \\pmb a^t \\bar {\\pmb x}_1 \\quad \\text{and} \\quad \\bar y_2 = \\pmb a^t \\bar {\\pmb x}_2\n\\]\nFisher의 방법은 변환된 일변량 변수 \\(y\\)가 두 집단 간의 차이를 최대로, 집단 내의 차이를 최소로 하도록 하는 선형변환 \\(\\pmb a\\)를 유도하는 것이다.\n두 집단 간의 차이를 최대로 하는 것은 두 평균의 차이 \\(|\\bar y_1 -\\bar y_2|\\)가 커지게 하는 것이고 집단 내의 차이를 최소로 하도록 하는 것은 집단내의 변동, 즉 집단내의 분산을 작게하는 것이다. 이러한 두 집단 간의 차이와 집단 내의 변동을 같이 반영할 수 있는 측도를 다음과 같이 생각하였다.\n\\[\n\\max_{\\pmb a} \\frac {| \\bar y_1 - \\bar y_2|} {s_y} =  \\max \\frac{ \\text{variation between groups}}{\\text{variation within group}}\n\\tag{5.15}\\]\n여기서 $s^2_y $는 두 집단의 특성값 \\(y\\)의 합동분산 추정량이다.\n\\[\ns^2_y =\\frac {\\sum_{j=1}^{ n_1}(y_{1j} -\\bar y_1)^2 + \\sum_{j=1}^{ n_2}(y_{2j} -\\bar y_2)^2 }{n_1+n_2-2}\n\\]\n이제 두 집단 간의 차이를 최대로, 집단 내의 변동를 최소로 하는 변환을 유도해보자. 식 5.15 에 제시된 값의 제곱이 가질 수 있는 상한(upper bound)을 유도하고 그 상한값을 취하는 선형변환 벡터 \\(\\pmb a\\)를 찾아보자.\n여기서 두 집단의 평균벡터의 차이 \\(\\pmb d\\)를 다음과 같이 정의한다.\n\\[\n\\pmb d =(\\bar {\\pmb x}_1 - \\bar {\\pmb x}_2)\n\\]\n이제 식 5.15 에 주어진 값의 제곱에 대한 상한을 유도해보자.\n\\[\n\\begin{aligned}\n\\frac {( \\bar y_1 - \\bar y_2)^2} {s^2_y}\n&=  \\frac{ ( \\pmb a^t \\bar {\\pmb x}_1 -  \\pmb a^t \\bar {\\pmb x}_2)^2}\n{ \\pmb a^t \\pmb S_{p}  \\pmb a } \\\\\n& =   \\frac{ [ \\pmb a^t (\\bar {\\pmb x}_1 - \\bar {\\pmb x}_2)]^2}\n{ \\pmb a^t \\pmb S_{p}  \\pmb a } \\\\\n& =   \\frac{ ( \\pmb a^t \\pmb d)^2}\n{ \\pmb a^t \\pmb S_{p}  \\pmb a } \\\\\n&=   \\frac{ ( \\pmb a^t  \\pmb S_{p}^{1/2} \\pmb S_{p}^{-1/2} \\pmb d)^2}\n{ \\pmb a^t \\pmb S_{p}  \\pmb a } \\\\\n& \\le   \\frac{ ( \\pmb a^t  \\pmb S_{p} \\pmb a) ( \\pmb d^t \\pmb S_{p}^{-1} \\pmb d)}\n{ \\pmb a^t \\pmb S_{p}  \\pmb a } \\\\\n&= \\pmb d^t \\pmb S^{-1}_{p} \\pmb d\n\\end{aligned}\n\\tag{5.16}\\]\n위에서 부등식은 코쉬-쉬바르쯔 부등식(Cauchy–Schwarz Inequality) 을 적용한 결과이며 부등식의 등호는 다음과 같은 경우에 성립한다.\n\\[\n\\pmb a = \\pmb S^{-1}_{p} \\pmb d = \\pmb S^{-1}_{p} (\\bar {\\pmb x}_1 - \\bar {\\pmb x}_2)\n\\tag{5.17}\\]\n\n\n\n\n\n\n코쉬-쉬바르쯔 부등식\n\n\n\n두 벡터 \\(\\pmb u\\)와 \\(\\pmb v\\)에 대하여 다음 부등식(Cauchy–Schwarz Inequality)이 성립한다.\n\\[\n|\\pmb u^t \\pmb v|^2 \\le (\\pmb u^t \\pmb u)(\\pmb v^t \\pmb v)\n\\] 부등식의 등호는 \\(\\pmb u\\)와 \\(\\pmb v\\)가 선형종속일 때, 즉 \\(\\pmb u = c \\pmb v\\) 인 경우 성립한다.\n식 5.16 에서 다음과 같이 벡터 \\(\\pmb u\\) 와 \\(\\pmb v\\) 를 적용하면 원하는 결과를 얻는다.\n\\[\n\\pmb u = \\pmb S_{p}^{1/2} \\pmb a \\quad \\text{and} \\quad \\pmb v = \\pmb S_{p}^{-1/2} \\pmb d\n\\]\n\n\n식 5.17 에서 유도한 선형변환 벡터 \\(\\pmb a\\)는 다변량 정규분포 가정하에서 ECM을 최소화하는 판별함수의 선형벡터 식 5.12 와 동일하다.\n더 나아가 예제 5.1 의 결과를 이용하면, 두 집단의 평균이 각각 \\(\\bar y_1\\) 과 \\(\\bar y_2\\) 이므로 새로운 관측값 \\(y_0 = \\pmb a^t \\pmb x_0\\) 의 값을 두 평균의 가운데 값, 즉 \\(m=(\\bar y_1 + \\bar y_2)/2\\)와 비교하여 판별할 수 있다. 즉, 개체의 특성값 \\(y_0 = \\pmb a^t \\pmb x_0\\)일 때 다음을 만족하면 집단 \\(P_1\\)으로 분류한다.\n\\[  \ny_0  &gt;  m\n\\]\n여기서\n\\[\ny_0= \\pmb a^t\\pmb x_0=  (\\bar {\\pmb x}_1-\\bar {\\pmb x}_2)^t \\pmb S_{p}^{-1} \\pmb x_0\n\\]\n\\[\nm=\\frac{1}{2} (\\bar {\\pmb x}_1-\\bar {\\pmb x}_2)^t \\pmb S_{p}^{-1} (\\bar\n{\\pmb x}_1+\\bar {\\pmb x}_2)= \\frac{1}{2} \\pmb a^t (\\bar\n{\\pmb x}_1+\\bar {\\pmb x}_2)  = \\frac{1}{2} {(\\bar y_1 +\\bar y_2} )\n\\]\n따라서 Fisher의 판별함수에 의한 분류 규칙은 다변량 정규분포 가정하에 ECM을 최소로 하는 규칙 식 5.14 과 동일하다.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>판별분석</span>"
    ]
  },
  {
    "objectID": "qmd/multivar-discrim.html#예제-잔디깎는-트렉터",
    "href": "qmd/multivar-discrim.html#예제-잔디깎는-트렉터",
    "title": "5  판별분석",
    "section": "5.4 예제: 잔디깎는 트렉터",
    "text": "5.4 예제: 잔디깎는 트렉터\n다음은 미국에서 한 소비용품 판매점이 잔디깍는 트랙터(lawn mower)의 소유 여부에 대한 가구의 소득과 집 크기의 관계를 알아보기 위하여 고객의 정보를 수집한 자료이다. 총 24개의 자료가 있고 트랙터를 소유하지 않는 집과 소유한 집이 각각 12개이다.\n변수 income 과 lotsize 는 각각 가구 소득과 집의 크기에 대한 변수이다. 트랙터를 소유한 상태를 나타내는 변수는 class 이며 값이 1이면 소유하지 않는 상태(NO,그룹 1), 2이면 소유한 상태(YES, 그룹 2) 를 나타낸다.\n\n# read data\ndf &lt;- read.csv(here(\"data\",\"lawn.csv\") , header=T, sep=\"\")\ndf$class &lt;- factor(df$class, levels=c(2,1), labels=c( \"NO\",\"YES\"))\nhead(df)\n\n  income lotsize class\n1   60.0    18.4   YES\n2   85.5    16.8   YES\n3   64.8    21.6   YES\n4   61.5    20.8   YES\n5   87.0    23.6   YES\n6  110.1    19.2   YES\n\n\n이제 트렉터 소유의 여부와 소득/집크기의 관계를 알아보기 위하여 이차원에 자료를 그림으로 나타내보자.\n\n# plot data wiyth different symbol by uisng ggplot2\n\ndf %&gt;% ggplot(aes(x=income,y=lotsize, shape=class, color=class)) + \n  geom_point(size=4, alpha = 0.7) +\n  theme_bw() + \n  labs(x=\"가구 소득\",y=\"집 면적 \",shape=\"소유 여부\", color = \"소유 여부\")\n\n\n\n\n\n\n\n\n이제 앞절에서 유도한 선형판별함수를 트렉터 자료에 적용하여 판별함수를 구해보자. 일단 표본 평균벡터와 합동 공분산 행렬을 계산한다.\n\n# 각 그룹의 표본 크기\nn1 &lt;- sum(df$class == \"NO\" )\nn2 &lt;- sum(df$class == \"YES\" )\n\nn1\n\n[1] 12\n\nn2\n\n[1] 12\n\n# 각 그룹의 평균벡터\nmean_vec &lt;- df %&gt;% \n   group_by(class) %&gt;%\n   summarise(across(c(income, lotsize), mean))\n\nmean_vec\n\n# A tibble: 2 × 3\n  class income lotsize\n  &lt;fct&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 NO      57.4    17.6\n2 YES     79.5    20.3\n\nmean_x1 &lt;- mean_vec %&gt;% dplyr::filter(class == \"NO\" ) %&gt;% \n  dplyr::select(income, lotsize) %&gt;% \n  as.matrix() %&gt;% t()\n\nmean_x2 &lt;- mean_vec %&gt;% dplyr::filter(class == \"YES\" ) %&gt;% \n  dplyr::select(income, lotsize) %&gt;% \n  as.matrix() %&gt;% t()\n\nmean_x1\n\n            [,1]\nincome  57.40000\nlotsize 17.63333\n\nmean_x2\n\n            [,1]\nincome  79.47500\nlotsize 20.26667\n\n# 각 그룹의 공분산 행렬\n\ncov_tbl &lt;- df %&gt;%\n  group_by(class) %&gt;%\n  summarise(cov = list(cov(across(c(income, lotsize)))), .groups = \"drop\")\n\ncov_x1 &lt;- cov_tbl %&gt;% filter(class == \"NO\" ) %&gt;% pull(cov) %&gt;% .[[1]]\ncov_x1\n\n            income   lotsize\nincome  200.705455 -2.589091\nlotsize  -2.589091  4.464242\n\ncov_x2 &lt;- cov_tbl %&gt;% filter(class == \"YES\" ) %&gt;% pull(cov) %&gt;% .[[1]]\ncov_x2\n\n           income    lotsize\nincome  352.64386 -11.818182\nlotsize -11.81818   4.082424\n\n# 합동 공분산 행렬\n#cov_p &lt;- ((n1-1)*cov_x1 + (n2-1)*cov_x2)/(n1+n2-2)\ncov_p &lt;- (n1*cov_x1 + n2*cov_x2)/(n1+n2)\ncov_p\n\n            income   lotsize\nincome  276.674659 -7.203636\nlotsize  -7.203636  4.273333\n\n\n이제 트렉터 자료에 적용하여 앞장에서 구한 최적의 판별 규칙을 유도해보자. 먼저 식 5.12 와 식 5.17 에 나타난 최적 변환 벡터 \\(\\pmb a\\) 와 상수 \\(m\\) 는 다음과 같이 구할 수 있다.\n\n# find discriminant function \na &lt;- solve(cov_p) %*%  (mean_x1 - mean_x2) \na\n\n              [,1]\nincome  -0.1002303\nlotsize -0.7851847\n\n\n\nm &lt;- t(mean_x1 - mean_x2) %*% solve(cov_p) %*% (mean_x1 + mean_x2)/2\nm\n\n          [,1]\n[1,] -21.73876\n\n\n따라서 새로운 특성값 벡터를 \\(\\pmb x_0= (x_{10},~x_{20})^t\\) 이라고 하면 ECM을 최소화하는 판별함수는 다음과 같이 주어진다. 즉, 다음 조건이 만족하면 그룹 1, 즉 트랙터를 사지 않는 그룹에 속한다.\n\\[\n(-0.1002303) \\times  (x_{10})  + (-0.7851847) \\times  (x_{20})  &gt; -21.7387617\n\\]\n만약 income 과 lotsize가 각각 70, 16 이라면 다음과 같이 \\(\\pmb a^t \\pmb x_0\\) 를 구할 수 있다.\n\nx_0 &lt;- matrix(c(70, 16),2,1)\nx_0\n\n     [,1]\n[1,]   70\n[2,]   16\n\nt(a) %*% x_0 \n\n          [,1]\n[1,] -19.57908\n\n\n다시 쓰면\n\\[\n(-0.1002303) \\times  (70)  + (-0.7851847) \\times  (16)  = -19.5790766\n\\] 따라서 -19.5790766 &lt; -21.7387617 이므로 그룹 1 에 속한다고 판별한다.즉 트랙터를 소유하지 않는 집단에 속한다고 판별한다.\n\nt(a) %*% x_0 &gt; m\n\n     [,1]\n[1,] TRUE\n\n\n즉, income 과 lotsize가 각각 70, 16 이면 \\(\\pmb a^t \\pmb x_0 &gt; m\\) 을 만족하므로 트렉터를 소유하지 않을 그룹에 속한다고 판별한다.\n트랙터를 소유한 집단과 소유하지 않은 집단에서 소득과 집크기에 대하여 이변량 정규분포를 가정하고 각 집단의 평균벡터와 공통 공분산을 구하여 이변량 정규분포의 확률밀도함수를 이차원 평면에 표시해보았다. 또한 앞에서 구한 선형 판별함수의 경계선 \\(\\pmb a^t \\pmb x = m\\) 을 표시하였다\n\n# 등고선을 위한 격자점 생성\ngrid &lt;- expand.grid(\n  income = seq(min(df$income) - 1, max(df$income) + 1, length = 100),\n  lotsize = seq(min(df$lotsize) - 1, max(df$lotsize) + 1, length = 100)\n)\n# 각 집단의 이변량 정규분포 확률밀도함수 계산\ngrid$dx1 &lt;- dmvnorm(grid[,c(\"income\",\"lotsize\")], mean = mean_x1, sigma = cov_p)\ngrid$dx2 &lt;- dmvnorm(grid[,c(\"income\",\"lotsize\")], mean = mean_x2, sigma = cov_p)\n\n# 산점도와 등고선, 판별 경계선 그리기 \ndf %&gt;% ggplot(aes(x=income,y=lotsize, shape=class, color=class)) + \n  geom_point(size=4, alpha = 0.9) +\n  # 평균벡터 표기\n  geom_point(data = mean_vec, aes(x=income, y=lotsize, color=class),  shape=3, size=5, stroke=2) +\n  # 등고선 1\n  geom_contour(\n    data = grid,\n    aes(x = income, y = lotsize, z = dx1),\n    color = \"blue\", linewidth = 0.2, bins = 6,\n    inherit.aes = FALSE\n  ) +\n  # 등고선 2\n  geom_contour(\n    data = grid,\n    aes(x = income, y = lotsize, z = dx2),\n    color = \"red\", linewidth = 0.2, bins = 6,\n    inherit.aes = FALSE\n  ) +\n  # 판별 경계선\n  geom_abline(\n    intercept = m/a[2], slope = -a[1]/a[2],\n    color = \"black\", linewidth = 1\n  ) +\n  theme_bw() + \n  labs(x=\"가구 소득\",y=\"집 면적 \",shape=\"소유 여부\", color = \"소유 여부\")\n\n\n\n\n\n\n\n\n패키지 MAASS 의 함수 lda()을 이용하면 앞에서 구한 Fisher 의 선형판별함수를 쉽게 구할 수 있다.\n\nfisher_model &lt;- lda(class ~ income + lotsize, data = df, method=\"moment\")\nfisher_model\n\nCall:\nlda(class ~ income + lotsize, data = df, method = \"moment\")\n\nPrior probabilities of groups:\n NO YES \n0.5 0.5 \n\nGroup means:\n    income  lotsize\nNO  57.400 17.63333\nYES 79.475 20.26667\n\nCoefficients of linear discriminants:\n              LD1\nincome  0.0484468\nlotsize 0.3795228\n\n# 판별 벡터\nfisher_model$scaling\n\n              LD1\nincome  0.0484468\nlotsize 0.3795228\n\n\n참고로 함수 lda 의 결과값인 Coefficients of linear discriminants 는 식 5.17 에서 구한 최적 변환 백터 \\(\\pmb a\\) 와 같은 방향의 벡터이지만 길이가 다른 점에 유의하자.\n\n# lda 함수의 결과와 비교\na/a[1]\n\n            [,1]\nincome  1.000000\nlotsize 7.833806\n\nfisher_model$scaling/fisher_model$scaling[1]\n\n             LD1\nincome  1.000000\nlotsize 7.833806\n\n\n이제 위에서 고려한 값, 즉 income 과 lotsize가 각각 70, 16 이라면 다음과 같이 새로운 데이터프레임을 만들고 predict 함수를 사용하여 앞에서 구한 판별 결과와 동일한 결과를 얻을 수 있다.\n\nnew_data &lt;- data.frame(income = 70, lotsize = 16)\npredict(fisher_model, newdata = new_data)\n\n$class\n[1] NO\nLevels: NO YES\n\n$posterior\n         NO       YES\n1 0.8965703 0.1034297\n\n$x\n        LD1\n1 -1.043894",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>판별분석</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html",
    "href": "qmd/math_mat_basic.html",
    "title": "부록 A — 행렬의 기초",
    "section": "",
    "text": "A.1 벡터와 행렬\n이 장에서는 회귀분석의 이론 전개에 필요한 행렬 이론과 선형 대수의 기초에 대하여 알아볼 것이다.\n다음 \\(p\\)-차원 벡터(vector) 또는 열벡터(column vector) \\(\\pmb a\\) 는 \\(p\\)개의 원소 \\(a_1, a_2, \\dots, a_p\\) 를 하나의 열(column)에 배치한 형태를 가진 개체이다.\n\\[\n\\pmb a =\n\\begin{bmatrix}\na_1 \\\\\na_2 \\\\\n\\vdots \\\\\na_p\n\\end{bmatrix}\n\\tag{A.1}\\]\n차원이 \\(n \\times p\\) 인 행렬 \\(\\pmb A\\) 는 다음과 같이 \\(n\\)개의 행과 \\(p\\) 개의 열에 원소 \\(a_{ij}\\)를 다음과 같이 배치한 형태를 가진다.\n\\[\n\\pmb A =\n\\begin{bmatrix}\na_{11} & a_{12} & \\dots & a_{1p} \\\\\na_{21} & a_{22} & \\dots & a_{2p} \\\\\n\\vdots & \\vdots &    & \\dots \\\\\na_{n1} & a_{n2} & \\dots & a_{np}\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#두-행렬의-덧셈",
    "href": "qmd/math_mat_basic.html#두-행렬의-덧셈",
    "title": "부록 A — 행렬의 기초",
    "section": "A.2 두 행렬의 덧셈",
    "text": "A.2 두 행렬의 덧셈\n두 행렬 \\(\\pmb A\\) 와 \\(\\pmb B\\) 를 더하는 규칙은 다음과 같다.\n\n두 행렬 \\(\\pmb A\\) 와 \\(\\pmb B\\) 는 행과 열의 갯수가 같아야 한다.\n\\(\\pmb A + \\pmb B = \\pmb C\\) 라고 하면, 덧셈의 결과로 만들어진 행렬 \\(\\pmb C\\)는 두 행렬과 같은 수의 행과 열을 가지면 각 원소는 다음과 같다.\n\n\\[ \\pmb A + \\pmb B = \\pmb C \\quad \\rightarrow \\quad c_{ij} = a_{ij} + b_{ij} \\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#스칼라곱",
    "href": "qmd/math_mat_basic.html#스칼라곱",
    "title": "부록 A — 행렬의 기초",
    "section": "A.3 스칼라곱",
    "text": "A.3 스칼라곱\n임의의 실수 \\(\\lambda\\) (스칼라)가 주어졌을 때, \\(\\lambda\\) 와 행렬 \\(\\pmb A\\)의 스칼라곱(scalar product) 는 행렬의 모든 원소에 \\(\\lambda\\) 를 곱해준 행렬로 정의된다.\n예를 들어 \\(\\lambda=2\\), \\(\\pmb A \\in \\RR^{2\\times 3}\\) 인 경우\n\\[\n\\lambda \\pmb A =\n2\n\\begin{bmatrix}\n1 & 2 & 3 \\\\\n-1 & 0 & 2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2 & 4 & 6 \\\\\n-2 & 0 & 4\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#벡터와-행렬의-곱셈",
    "href": "qmd/math_mat_basic.html#벡터와-행렬의-곱셈",
    "title": "부록 A — 행렬의 기초",
    "section": "A.4 벡터와 행렬의 곱셈",
    "text": "A.4 벡터와 행렬의 곱셈\n\\(n \\times p\\) 인 행렬 \\(\\pmb A\\) 와 \\(p\\)-차원 벡터(vector) \\(\\pmb b\\)는 다음과 같이 두 개의 서로 다른 형태로 나타낼 수 있다.\n\nA.4.1 행과 열의 내적\n먼저 행렬과 벡터의 곱셈은 행렬 \\(\\pmb A\\) 의 행벡터와 벡터 \\(\\pmb b\\) 의 내적(inner product)로 나타낼 수 있다.\n\\[\n\\begin{aligned}\n{\\pmb A} {\\pmb b} & =\n\\begin{bmatrix}\na_{11} & a_{12} & \\dots & a_{1p} \\\\\na_{21} & a_{22} & \\dots & a_{2p} \\\\\n\\vdots & \\vdots &    & \\dots \\\\\na_{n1} & a_{n2} & \\dots & a_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_p\n\\end{bmatrix} \\\\\n& =\n\\begin{bmatrix}\n{\\pmb r}^t_1 \\\\\n{\\pmb r}^t_2 \\\\\n\\vdots \\\\\n{\\pmb r}^t_n\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_p\n\\end{bmatrix}\n\\quad\n\\text{ where }\n{\\pmb r}^t_i =\n\\begin{bmatrix}\na_{i1} & a_{i2} & \\dots & a_{ip}\n\\end{bmatrix}  \\\\\n& =\n\\begin{bmatrix}\n{\\pmb r}^t_1 {\\pmb b} \\\\\n{\\pmb r}^t_2 {\\pmb b} \\\\\n\\vdots \\\\\n{\\pmb r}^t_n {\\pmb b}\n\\end{bmatrix}  \n=\n\\begin{bmatrix}\n\\sum_{j=1}^p a_{1j} b_j \\\\\n\\sum_{j=1}^p a_{2j} b_j \\\\\n\\vdots \\\\\n\\sum_{j=1}^p a_{nj} b_j\n\\end{bmatrix} \\\\\n& =\n\\begin{bmatrix}\n&lt;\\pmb r_1, \\pmb b&gt;  \\\\\n&lt;\\pmb r_2, \\pmb b&gt; \\\\\n\\vdots \\\\\n&lt;\\pmb r_n, \\pmb b&gt;\n\\end{bmatrix}\n\\end{aligned}\n\\]\n위에서 \\(&lt; \\pmb a, \\pmb b&gt;\\) 는 다음과 같은 두 벡터의 내적(inner product)을 의미한다.\n\\[ &lt; \\pmb a, \\pmb b&gt; = {\\pmb a}^t {\\pmb b} = \\sum_{i=1}^p a_i b_i \\]\n\n\nA.4.2 열벡터의 선형조합\n이제 행렬과 벡터의 곱셈을 행렬을 구성하는 열벡터들의 선형조합(linear combination)으로 나타낼 수 있다.\n\\[\n\\begin{aligned}\n{\\pmb A} {\\pmb b} & =\n\\begin{bmatrix}\na_{11} & a_{12} & \\dots & a_{1p} \\\\\na_{21} & a_{22} & \\dots & a_{2p} \\\\\n\\vdots & \\vdots &    & \\dots \\\\\na_{n1} & a_{n2} & \\dots & a_{np}\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_p\n\\end{bmatrix} \\\\\n& =\n\\begin{bmatrix}\n{\\pmb c}_1 & {\\pmb c}_2 & \\dots & {\\pmb c}_p\n\\end{bmatrix}\n\\begin{bmatrix}\nb_1 \\\\\nb_2 \\\\\n\\vdots \\\\\nb_p\n\\end{bmatrix}\n\\quad\n\\text{ where }\n{\\pmb c}_j =\n\\begin{bmatrix}\na_{1j} \\\\\na_{2j} \\\\\n\\vdots \\\\\na_{nj}\n\\end{bmatrix} \\\\\n& =\nb_1\n\\begin{bmatrix}\na_{11} \\\\\na_{21} \\\\\n\\vdots \\\\\na_{n1}\n\\end{bmatrix}\n+\nb_2\n\\begin{bmatrix}\na_{12} \\\\\na_{22} \\\\\n\\vdots \\\\\na_{n2}\n\\end{bmatrix}\n+ \\cdots +\nb_p\n\\begin{bmatrix}\na_{1p} \\\\\na_{2p} \\\\\n\\vdots \\\\\na_{np}\n\\end{bmatrix}  \\\\\n& =\nb_1 {\\pmb c}_1 + b_2 {\\pmb c}_2 + \\cdots + b_p {\\pmb c}_p \\\\\n\\end{aligned}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#행렬의-전치",
    "href": "qmd/math_mat_basic.html#행렬의-전치",
    "title": "부록 A — 행렬의 기초",
    "section": "A.5 행렬의 전치",
    "text": "A.5 행렬의 전치\n\\(\\pmb A^t\\)는 행렬의 전치(transpose)를 나타낸다. 행렬의 전치는 원소의 행과 열을 바꾸어 만든 행렬이다.\n\\[\n{\\pmb A}  =\n\\begin{bmatrix}\na_{11} & a_{12} & \\dots & a_{1p} \\\\\na_{21} & a_{22} & \\dots & a_{2p} \\\\\n\\vdots & \\vdots &    & \\dots \\\\\na_{n1} & a_{n2} & \\dots & a_{np}\n\\end{bmatrix}\n= \\{ a_{ij} \\}_{ n \\times p}\n\\quad\n\\rightarrow\n\\quad\n{\\pmb A}^t  =\n\\begin{bmatrix}\na_{11} & a_{21} & \\dots & a_{n1} \\\\\na_{12} & a_{22} & \\dots & a_{n2} \\\\\n\\vdots & \\vdots &    & \\dots \\\\\na_{1p} & a_{2p} & \\dots & a_{np}\n\\end{bmatrix}\n= \\{ a_{ji} \\}_{ p \\times n}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#행렬의-곱셈",
    "href": "qmd/math_mat_basic.html#행렬의-곱셈",
    "title": "부록 A — 행렬의 기초",
    "section": "A.6 행렬의 곱셈",
    "text": "A.6 행렬의 곱셈\n먼저 두 행렬 \\(\\pmb A\\) 와 \\(\\pmb B\\) 의 곱셈\n\\[ \\pmb A \\times \\pmb B \\equiv \\pmb A \\pmb B \\]\n을 정의하려면 다음과 같은 조건이 만족되어야 한다.\n\n행렬 \\(\\pmb A\\) 의 열의 갯수와 행렬 \\(\\pmb B\\) 의 행의 갯수가 같아야 한다\n\n따라서 두 행렬의 곱셈은 순서를 바꾸면 정의 자체가 안될 수 있다.\n이제 두 행렬 \\(\\pmb A \\in \\RR^{m \\times n}\\) 와 \\(\\pmb B \\in \\RR^{n \\times k}\\)의 곱셈은 다음과 같이 정의된다.\n\\[ \\pmb A \\pmb B =  \\pmb C\\]\n행렬 \\(\\pmb C\\) 는 \\(m\\) 개의 행과 \\(k\\)개의 열로 구성된 행렬이며(\\(\\pmb C \\in \\RR^{m \\times k}\\)) 각 원소 \\(c_{ij}\\)는 다음과 같이 정의된다.\n\\[  c_{ij} = \\sum_{l=1}^n a_{il} b_{lk}, \\quad i=1,2,\\dots,m; j=1,2,\\dots,k \\]\n먼저 간단한 예제로 다음과 같은 두 개의 행렬의 곱을 생각해 보자.\n\\[\n\\pmb A \\pmb B =\n\\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix}\n\\begin{bmatrix}\n0 & 1 \\\\\n-1 & 2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n(1)(0) + (2)(-1) & (1)(1) + (2)(2) \\\\\n(3)(0) + (4)(-1) & (3)(1) + (4)(2)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n-2 & 5 \\\\\n-4 & 11\n\\end{bmatrix}\n\\]\n곱하는 순서를 바꾸어 계산해 보자.\n\\[\n\\pmb B \\pmb A =\n\\begin{bmatrix}\n0 & 1 \\\\\n-1 & 2\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 2 \\\\\n3 & 4\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n(0)(1) + (1)(3) & (0)(2) + (1)(4) \\\\\n(-1)(1) + (2)(3) & (-1)(2) + (2)(4)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n3 & 4 \\\\\n5 & 6\n\\end{bmatrix}\n\\]\n위 두 결과를 보면 행렬의 곱셈에서는 교환법칙이 성립하지 않음을 알 수 있다.\n이제 차원이 다른 두 행렬의 곱셈을 살펴보자.\n\\[\n\\pmb A =\n\\begin{bmatrix}\n1 & 2 & 3\\\\\n3 & 2 & 1\n\\end{bmatrix},\n\\quad\n\\pmb B =\n\\begin{bmatrix}\n0 & 2 \\\\\n1 & -1 \\\\\n0 & 1\n\\end{bmatrix}\n\\]\n두 행렬의 곱셈은 다음과 같이 계산할 수 있다.\n\\[\n\\pmb A \\pmb B =\n\\begin{bmatrix}\n1 & 2 & 3\\\\\n3 & 2 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n0 & 2 \\\\\n1 & -1 \\\\\n0 & 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2 & 3 \\\\\n2 & 5\n\\end{bmatrix}\n\\]\n두 행렬의 곱하는 순서를 바꾸면 차원이 전혀 다른 행렬이 얻어진다.\n\\[\n\\pmb B \\pmb A =\n\\begin{bmatrix}\n0 & 2 \\\\\n1 & -1 \\\\\n0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 2 & 3\\\\\n3 & 2 & 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n6 & 4 & 2 \\\\\n-2 & 0 & 2 \\\\\n3 & 2 & 1\n\\end{bmatrix}\n\\]\n행렬의 곱셈은 교환법칙이 성립하지 않는다.\n\\[  \\pmb A \\pmb B \\ne  \\pmb B \\pmb A \\tag{A.2}\\]\n\n\n\n\n\n\n주의\n\n\n\n교환법칙이 성립하지 않는다는 의미는 식 A.2 이 언제나 성립한다는 의미는 아니다. 아래와 같이 특별한 경우 교환법칙이 성립하는 경우도 있다.\n\\[\n\\begin{bmatrix}\n1 & 2 \\\\\n1 & 3\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 2 \\\\\n1 & 3\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 2 \\\\\n1 & 3\n\\end{bmatrix}\n\\]\n\n\n\n행렬의 곱셈은 결합법칙과 배분법칙은 성립한다.\n\n\\[ (\\pmb A \\pmb B) \\pmb C = \\pmb A (\\pmb B \\pmb C) \\]\n\\[ (\\pmb A + \\pmb B) \\pmb C = \\pmb A \\pmb C +  \\pmb B \\pmb C \\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#단위벡터와-항등행렬",
    "href": "qmd/math_mat_basic.html#단위벡터와-항등행렬",
    "title": "부록 A — 행렬의 기초",
    "section": "A.7 단위벡터와 항등행렬",
    "text": "A.7 단위벡터와 항등행렬\n\\(i\\)번째 단위벡터 \\(\\pmb e_i\\)를 정의하자. 단위벡터 \\(\\pmb e_i\\)는 \\(n\\)- 차원 벡터로서 \\(i\\)번째 원소만 1이고 나머지는 0인 벡터이다.\n\\[ \\pmb e_i =\n\\begin{bmatrix}\n0 \\\\\n0 \\\\\n\\vdots \\\\\n0 \\\\  \n1 \\\\\n0 \\\\\n\\vdots \\\\\n0\n\\end{bmatrix}\n\\]\n즉 \\(n\\)-차원 항등행렬 \\(\\pmb I\\)는 n개의 단위벡터들을 모아놓은 것이다. 단위행렬은 대각원소가 1이고 나머지는 0인 정방행렬이다.\n\\[  \\pmb I = [ \\pmb e_1 ~~ \\pmb e_2 ~~ \\dots ~~ \\pmb e_n ] \\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#대각합",
    "href": "qmd/math_mat_basic.html#대각합",
    "title": "부록 A — 행렬의 기초",
    "section": "A.8 대각합",
    "text": "A.8 대각합\n\\(\\pmb A = \\{ a_{ij} \\}\\)를 \\(n \\times n\\) 정방행렬(square matrix)인 경우, 행렬의 대각 원소(diagonal element)들의 합(trace)을 \\(tr(\\pmb A)\\)로 표시한다.\n\\[ tr(\\pmb A) = \\sum_{i=1}^n a_{ii} \\]\n두 행렬의 덧셈(뺄셈)에 대한 대각합에 대한 성질들은 다음과 같다.\n\\[ tr( {\\pmb A} \\pm {\\pmb B}) = tr({\\pmb A}) \\pm tr({\\pmb B}) \\]\n\n\n\n\n\n\n주의\n\n\n\n행렬의 곱셈은 일반적으로 교환법칙이 성립하지 않지만 대각합의 연산은 교환법칙이 성립한다.\n\\[  tr(\\pmb A \\pmb B)  = tr( \\pmb B \\pmb A) \\]\n\n\n대각합은 교환법칙이 성립히기 떄문에 다음과 같은 성질이 성립한다.\n\\[\n\\operatorname{tr}(\\pmb {A} \\pmb {K} \\pmb {L})=\\operatorname{tr}(\\pmb {K} \\pmb {L} \\pmb {A})\n\\]\n벡터의 연산에서도 대각합의 교환법칙이 성립되어 다음과 같은 유용한 식이 성립한다.\n\\[\n\\operatorname{tr}\\left(\\pmb {x} \\pmb {y}^t \\right)=\\operatorname{tr}\\left(\\pmb {y}^t  \\pmb {x}\\right)=\\pmb {y}^t  \\pmb {x} \\in \\mathbb{R} .\n\\]\n대각합의 교환법칙때문에 어떤 행렬의 앞에 특정 행렬을 곱하고, 뒤에 역행렬을 곱해도 대각합은 변하지 않는다.\n\\[\n\\operatorname{tr}\\left(\\pmb {S}^{-1} \\pmb {A} \\pmb {S}\\right) = \\operatorname{tr}\\left(\\pmb {A} \\pmb {S} \\pmb {S}^{-1}\\right)=\\operatorname{tr}(\\pmb {A})\n\\]\n대각합에 대한 그 밖의 성질들은 다음과 같다.\n\n\\(\\operatorname{tr}(\\alpha \\pmb {A})=\\alpha \\operatorname{tr}(\\pmb {A}), \\alpha \\in \\mathbb{R}\\) for \\(\\pmb {A} \\in \\mathbb{R}^{n \\times n}\\)\n\\(\\operatorname{tr}\\left(\\pmb {I}_n\\right)=n\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#sec-mat-determ",
    "href": "qmd/math_mat_basic.html#sec-mat-determ",
    "title": "부록 A — 행렬의 기초",
    "section": "A.9 행렬식",
    "text": "A.9 행렬식\n\\(\\pmb A\\)의 행렬식(determinant)을 \\(det(\\pmb A)=|\\pmb A|\\)로 표기한다.\n이차원 행렬 \\(\\pmb A\\) 의 행렬식은 다음과 같이 계산한다.\n\\[\n\\operatorname{det}( \\pmb {A})=\\left|\\begin{array}{ll}\na_{11} & a_{12} \\\\\na_{21} & a_{22}\n\\end{array}\\right|=a_{11} a_{22}-a_{12} a_{21} .\n\\]\n만약 행렬 \\(\\pmb A\\)가 대각행렬(diagonal matrix)이면 \\(|\\pmb A|\\)는 행렬의 대각원소의 곱이다 (\\(| \\pmb A| =\\prod a_{ii}\\)).\n두 행렬의 곱의 행렬식은 각 행렬의 행렬식의 곱이다.\n\\[ |\\pmb A \\pmb B | = | \\pmb A| |\\pmb B| \\]\n행렬식에 대한 유용한 공식들은 다음과 같다.\n\n\\(|{\\pmb A}^t| = |{\\pmb A}|\\)\n\\(|c {\\pmb A}| = c^n |{\\pmb A}|\\)\n\n만약 행렬 \\(\\pmb A\\)가 다음과 같은 분할행렬(partitioned matrix) 의 형태를 가지면\n\\[\n\\pmb A =\n\\begin{bmatrix}\n{\\pmb A}_{11} & {\\pmb A}_{12} \\\\\n{\\pmb 0} & {\\pmb A}_{22}\n\\end{bmatrix}\n\\]\n행렬 \\(\\pmb A\\)의 행렬식은 다음과 같이 주어진다.\n\\[ |{\\pmb A}| = |{\\pmb A}_{11}| |{\\pmb A}_{22} | \\]\n다음과 같은 행렬식에 대한 공식도 유용하다. p-차원 행렬 \\(\\pmb A\\)가 역행렬이 존재하고 벡터 \\(\\pmb u\\) 와 \\(\\pmb v\\) 에 대하여\n\\[ | \\pmb A + \\pmb u \\pmb v^t | = | \\pmb A | (1 + \\pmb v^t \\pmb A^{-1} \\pmb u)  \\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#역행렬",
    "href": "qmd/math_mat_basic.html#역행렬",
    "title": "부록 A — 행렬의 기초",
    "section": "A.10 역행렬",
    "text": "A.10 역행렬\n만약 정방행렬 \\(\\pmb A\\)가 다음과 같은 조건을 만족하면 정칙행렬(invertible matrix 또는 nonsingular matrix)이라고 부른다.\n\\[  \\pmb A \\pmb A^{-1} = \\pmb A^{-1} \\pmb A = \\pmb I \\] 이경우 \\(\\pmb A^{-1}\\) 를 행렬 \\(\\pmb A\\)의 역행렬(inverse matrix) 이라고 정의한다.\n역행렬이 존재할 조건은 행렬 \\(\\pmb A\\)의 행렬식이 0이 아니어야 한다.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#직교행렬",
    "href": "qmd/math_mat_basic.html#직교행렬",
    "title": "부록 A — 행렬의 기초",
    "section": "A.11 직교행렬",
    "text": "A.11 직교행렬\n만약 정방행렬 \\(\\pmb P\\)가 다음과 같은 조건을 만족하면 직교행렬(orthogonal matrix)라고 부른다.\n\\[  \\pmb P \\pmb P^t = \\pmb P^t \\pmb P = \\pmb I \\]\n직교행렬의 정의에서 주의할 점은 $P P^t = I $ 와 \\(\\pmb P^t \\pmb P = \\pmb I\\) 이 모두 성립하해야 한다는 점이다.\n행렬 \\(\\pmb P\\) 의 역행렬은 \\(\\pmb P^t\\) 이다.\n\\[ \\pmb P^{-1} = \\pmb P^t\\]\n만약 \\(\\pmb P\\)가 직교행렬이면 다음과 같은 성질을 가진다.\n\n\\(| \\pmb P | = \\pm 1\\) , 왜냐하면 \\[  | \\pmb P \\pmb P^t | = | \\pmb P | |\\pmb P^t |  = | \\pmb P|^2 = |\\pmb I| =1 \\]\n임의의 정방행렬 \\(\\pmb A\\)에 대하여 다음이 성립한다. \\[ tr(\\pmb P \\pmb A \\pmb P^t) = tr(\\pmb A \\pmb P^t \\pmb P) = tr(\\pmb A) \\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/math_mat_basic.html#우드베리-공식",
    "href": "qmd/math_mat_basic.html#우드베리-공식",
    "title": "부록 A — 행렬의 기초",
    "section": "A.12 우드베리 공식",
    "text": "A.12 우드베리 공식\n다음은 우드베리공식(Woodbury formula) 과 파생된 유용한 공식들이다.\n\\[\n(\\pmb A+\\pmb U\\pmb C\\pmb V)^{-1} = \\pmb A^{-1}-\\pmb A^{-1} \\pmb U (\\pmb C^{-1} + \\pmb V \\pmb A^{-1}\\pmb U)^{-1} \\pmb V \\pmb A^{-1}\n\\]\n\\[\n(\\pmb I+\\pmb U \\pmb C\\pmb V)^{-1} = \\pmb I - \\pmb U (\\pmb C^{-1} + \\pmb V \\pmb U)^{-1} \\pmb V\n\\]\n\\[ (\\pmb A+\\pmb u\\pmb v^t)^{-1} = \\pmb A^{-1} - \\frac{ \\pmb A^{-1} \\pmb u\\pmb v^t \\pmb A^{-1}}{1+\\pmb v^t \\pmb A^{-1}\\pmb u}  \\tag{A.3}\\]\n\\[\n(a \\pmb I_n + b \\pmb 1_n \\pmb 1_n^t)^{-1} = \\frac{1}{a} \\left [ \\pmb I_n - \\frac{b}{a+nb} \\pmb 1 \\pmb 1^t \\right ]\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>행렬의 기초</span>"
    ]
  },
  {
    "objectID": "qmd/app-likelihood-ratio.html",
    "href": "qmd/app-likelihood-ratio.html",
    "title": "부록 B — 가능도비 검정",
    "section": "",
    "text": "B.1 가능도비 검정의 기초\n가능도비 검정(likelihood ratio test) 은 제약 있는 모형과 제약 없는 모형의 최대가능도 함수(maximum likelihood function)의 비율를 이용하여 두 모형을 비교하는 검정이며 통계적 가설 검정에 널리 사용되고 있다.\n먼저 확률 변수 또는 확률 벡터 \\(\\pmb X\\) 가 확률 밀도 함수 \\(f(\\pmb X | \\pmb \\theta)\\) 를 따른다고 가정하자. 또한 다음과 같은 귀무 가설 검정을 고려하자. 또한 모수벡터 \\(\\pmb \\theta\\) 는 전체 모수 공간 \\(\\pmb \\Theta\\) 에 속한다고 가정한다.\n\\[\nH_0: \\pmb \\theta \\in {\\pmb \\Theta}_0 \\quad \\text{ vs } \\quad H_a: \\pmb \\theta \\in {\\pmb \\Theta} \\setminus {\\pmb \\Theta}_0\n\\tag{B.1}\\]\n위의 가설에서 귀무 가설 \\(H_0\\) 는 모수 공간 \\(\\pmb \\Theta\\) 의 부분 집합 \\(\\pmb \\Theta_0\\) 에 모수가 속한다는 것 (모수에 대한 제약조건)을 의미한다.\n이러한 가설 검정을 위하여 표본 벡터 \\(\\pmb X_1, \\ldots, \\pmb  X_n\\) 에 대한 가능도 함수 \\(L(\\pmb \\theta)\\) 와 로그 가능도 함수 \\(\\ell(\\pmb \\theta)\\)는 다음과 같이 정의된다. 참고로 가능도 함수는 주어진 표본의 값에 대하여 모수 \\(\\pmb \\theta\\) 의 함수로 생각할 수 있다.\n\\[\n\\begin{aligned}\nL(\\pmb \\theta) & = \\prod_{i=1}^n f(\\pmb X_i| \\pmb \\theta) \\\\\n\\ell(\\pmb \\theta) & = \\log \\prod_{i=1}^n f(\\pmb X_i| \\pmb \\theta) \\\\\n&= \\sum_{i=1}^n \\log f(\\pmb X_i| \\pmb \\theta)\n\\end{aligned}\n\\]\n이제 최대 가능도 추정을 다음 두 개의 경우에 대하여 고려해 보자.\n제약이 있는 경우에 대한 최대 가능도 추정량은 다음의 조건을 만족하는 경우\n\\[\n\\hat{\\pmb \\theta}_0 = \\arg\\max_{\\pmb \\theta \\in \\pmb \\Theta_0} L(\\pmb \\theta)\n\\]\n제약이 없는 경우에 대한 최대 가능도 추정량은 다음의 조건을 만족하는 경우니다.\n\\[\n\\hat{\\pmb \\theta} = \\arg\\max_{\\pmb \\theta \\in \\pmb \\Theta} L(\\pmb \\theta)\n\\]\n이제 두 경우에 대한 최대 가능도 추정량을 이용하여 가능도비 검정 통계량 \\(\\Lambda\\) 를 다음과 같이 정의한다.\n\\[\n\\begin{aligned}\n  \\Lambda & =\\frac{\\sup_{\\pmb \\theta \\in \\pmb \\Theta_0} L(\\pmb \\theta)}{\\sup_{\\pmb \\theta \\in \\pmb \\Theta} L(\\pmb \\theta)} \\\\\n  & =\\frac{L(\\hat{\\pmb \\theta}_0)}{L(\\hat{\\pmb \\theta})} \\in (0,1]\n\\end{aligned}\n\\]\n가능도비 \\(\\Lambda\\) 는 귀무 가설이 참일 때 1에 가까운 값을 가지며, 실제 모수가 귀무 가설의 제약조건에서 멀어지면 0에 가까운 값을 가진다. 따라서 귀무 가설을 기각하기 위한 기각역은 \\(\\Lambda\\) 가 작은 값이 되는 영역으로 설정한다. 또한 가설 검정의 편의성을 위하여 가능도비에 로그를 취하고 \\(-2\\) 를 취한 값을 검정에 이용한다.\n\\[\n\\lambda = -2 \\log \\Lambda = -2 \\left\\{ \\ell(\\hat{\\pmb \\theta}_0) - \\ell(\\hat{\\pmb \\theta}) \\right\\} \\in [0, \\infty)\n\\tag{B.2}\\]\n이제 위의 식에서 정의된 \\(\\lambda\\) 는 값이 크면 클수록 귀무가설에 반대되는 증거이다. 따라서 \\(\\lambda\\)의 값이 주어진 기각역 \\(c\\) 보다 크면 귀무 가설을 기각한다.\n\\[\n\\text{reject } H_0 \\quad \\text{ if } \\lambda &gt; c\n\\]\n기각역 \\(c\\) 는 \\(\\lambda\\) 에 비례하는 적절한 검정 통계량을 찾은 다음, 주어진 확률 분포와 표본의 갯수에 따라서 검정 통계량의 정확한 분포를 구하여 유도할 수 있다. 하지만 대부분의 경우에는 \\(\\lambda\\) 의 다음과 같은 점근적 성질(표본의 개수가 증가할 때 극한 분포를 이용)을 이용하여 기각역을 유도한다(Wilks’ theorem)\n\\[\n\\lambda = -2\\log\\Lambda \\rightarrow_{d} \\chi^2_{\\nu}\n\\] 위의 성질에서 \\(\\rightarrow_{d}\\) 는 분포의 수렴을 의미하며, \\(\\chi^2_\\nu\\) 는 자유도 \\(\\nu\\) 인 카이제곱 분포를 나타낸다. 자유도 \\(\\nu\\) 는 전체 모수 공간과 제약조건 공간 차원의 차이이며 다음과 같이 계산된다.\n\\[\n\\nu = \\dim(\\pmb \\Theta)-\\dim( \\pmb \\Theta_0)\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>가능도비 검정</span>"
    ]
  },
  {
    "objectID": "qmd/app-likelihood-ratio.html#가능도비-검정의-기초",
    "href": "qmd/app-likelihood-ratio.html#가능도비-검정의-기초",
    "title": "부록 B — 가능도비 검정",
    "section": "",
    "text": "제약이 있는 경우, 즉 귀무 가설이 참인 경우: \\(\\theta \\in \\pmb \\Theta_0\\)\n\n\n\n\n제약이 없는 경우, 즉 귀무 가설이 거짓인 경우",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>가능도비 검정</span>"
    ]
  },
  {
    "objectID": "qmd/app-likelihood-ratio.html#다변량-정규분포의-가능도비-검정",
    "href": "qmd/app-likelihood-ratio.html#다변량-정규분포의-가능도비-검정",
    "title": "부록 B — 가능도비 검정",
    "section": "B.2 다변량 정규분포의 가능도비 검정",
    "text": "B.2 다변량 정규분포의 가능도비 검정\n\nB.2.1 두 평균벡터의 비교\n확률 벡터 \\(\\pmb X\\) 과 \\(\\pmb Y\\) 가 평균이 각각 \\(\\pmb \\mu_1\\), \\(\\pmb \\mu_2\\) 이고 공분산이 \\(\\pmb \\Sigma\\) 인 p-차원 다변량 정규 분포를 따른다고 가정하자.\n\\[ \\pmb X \\sim N_p(\\pmb \\mu_1, \\pmb \\Sigma), \\quad \\pmb Y \\sim N_p(\\pmb \\mu_2, \\pmb \\Sigma) \\] 다변량 정규 분포의 확률밀도함수는 다음과 같이 주어진다.\n\\[\nf_p(\\pmb X \\mid {\\pmb \\mu},{\\pmb \\Sigma}  )= |2 \\pi \\pmb \\Sigma|^{-1/2}\n\\exp \\{ - \\tfrac{1}{2} ( \\pmb X -\\pmb \\mu)^t {\\pmb \\Sigma}^{-1}( \\pmb X-\\pmb \\mu) \\}\n\\]\n더 나아가 다음과 같은 가설 검정을 고려하자.\n\\[\nH_0 : \\pmb \\mu_1 = \\pmb \\mu_2 \\text{ vs } H_a: \\pmb \\mu_1 \\neq \\pmb \\mu_2\n\\]\n이제 가설 검정을 위하여 두 그룹에서 각각 \\(n_1, n_2\\)개의 다변량 표본이 관측되었다고 하자.\n\\[\n\\pmb X_1, \\pmb X_2, \\dots, \\pmb X_{n_1} \\sim_{IID} N(\\pmb \\mu_1, \\pmb \\Sigma), \\quad \\pmb Y_1, \\pmb Y_2, \\dots, \\pmb Y_{n_2} \\sim_{IID} N(\\pmb \\mu_2, \\pmb \\Sigma)\n\\] ### 로그 가능도 함수\n이제 로그 가능도 함수를 정의하자. 먼저 제약 조건이 없는 경우를 고려하자.\n\\[\n\\begin{aligned}\n\\ell({\\pmb \\mu_1},{\\pmb \\mu_2},{\\pmb \\Sigma}) &=\n\\log L({\\pmb \\mu_1},{\\pmb \\mu_2},{\\pmb \\Sigma}) \\\\\n& = \\log \\prod_{i=1}^{n_1} f_p(\\pmb X_i \\mid {\\pmb \\mu_1},{\\pmb \\Sigma} ) \\prod_{i=1}^{n_2} f_p(\\pmb Y_i \\mid {\\pmb \\mu_2},{\\pmb \\Sigma} ) \\\\\n& = \\sum_{i=1}^{n_1} \\log f_p(\\pmb X_i \\mid {\\pmb \\mu_1},{\\pmb \\Sigma} ) + \\sum_{i=1}^{n_2} \\log f_p(\\pmb Y_i \\mid {\\pmb \\mu_2},{\\pmb \\Sigma} ) \\\\\n& = -\\frac{n_1 + n_2 }{2}\\log|2\\pi \\pmb \\Sigma| \\\\\n& ~~ -\\frac{1}{2} \\Bigg [ \\sum_{i=1}^{n_1} (\\pmb X_i - \\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1) + \\sum_{i=1}^{n_2} (\\pmb Y_i - \\pmb \\mu_2)^t \\pmb \\Sigma^{-1} (\\pmb Y_i - \\pmb \\mu_2) \\Bigg ]\n\\end{aligned}\n\\tag{B.3}\\]\n만약 귀무 가설이 참이라면 \\(\\pmb \\mu_1 = \\pmb \\mu_2 = \\pmb \\mu\\) 이므로 로그 가능도 함수는 다음과 같이 주어진다.\n\\[\n\\begin{aligned}\n\\ell({\\pmb \\mu},{\\pmb \\Sigma}) &=\n\\log L({\\pmb \\mu},{\\pmb \\Sigma}) \\\\\n& = \\log \\prod_{i=1}^{n_1} f_p(\\pmb X_i \\mid {\\pmb \\mu},{\\pmb \\Sigma} ) \\prod_{i=1}^{n_2} f_p(\\pmb Y_i \\mid {\\pmb \\mu},{\\pmb \\Sigma} ) \\\\\n& = \\sum_{i=1}^{n_1} \\log f_p(\\pmb X_i \\mid {\\pmb \\mu},{\\pmb \\Sigma} ) + \\sum_{i=1}^{n_2} \\log f_p(\\pmb Y_i \\mid {\\pmb \\mu},{\\pmb \\Sigma} ) \\\\\n& = -\\frac{n_1 + n_2 }{2}\\log|2\\pi \\pmb \\Sigma| \\\\\n& ~~ -\\frac{1}{2} \\Bigg [ \\sum_{i=1}^{n_1} (\\pmb X_i - \\pmb \\mu)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu) + \\sum_{i=1}^{n_2} (\\pmb Y_i - \\pmb \\mu)^t \\pmb \\Sigma^{-1} (\\pmb Y_i - \\pmb \\mu) \\Bigg ]\n\\end{aligned}\n\\tag{B.4}\\]\n\n\nB.2.2 재곱합의 분해\n이제 이차형식의 다음과 같은 대각합(trace) 표현을 이용하면\n\\[\n{\\pmb x}^t \\pmb A {\\pmb x} =tr({\\pmb x}^t \\pmb A {\\pmb x}) = tr(\\pmb A {\\pmb x} {\\pmb x}^t )\n\\]\n로그 가능도 함수에 나타나는 제곱합 항들을 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\sum_{i=1}^{n_1} (\\pmb X_i - \\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1)\n&=\n\\operatorname{tr} \\Bigg [ \\sum_{i=1}^{n_1} (\\pmb X_i - \\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1) \\Bigg ] \\\\\n&=\n\\sum_{i=1}^{n_1}  \\operatorname{tr} \\Bigg [ (\\pmb X_i - \\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1) \\Bigg ] \\\\\n&=\n\\sum_{i=1}^{n_1}  \\operatorname{tr} \\Bigg [ \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1) (\\pmb X_i - \\pmb \\mu_1)^t  \\Bigg  ] \\\\\n  &=\n\\operatorname{tr} \\Bigg [ \\pmb \\Sigma^{-1}  \\sum_{i=1}^{n_1}  (\\pmb X_i - \\pmb \\mu_1) (\\pmb X_i - \\pmb \\mu_1)^t  \\Bigg  ]\n\\end{aligned}\n\\tag{B.5}\\]\n또한 위의 식에서 \\(\\pmb X_i - \\pmb \\mu_1\\) 를 \\((\\pmb X_i - \\bar{\\pmb X}_1) + (\\bar{\\pmb X}_1 - \\pmb \\mu_1)\\) 로 전개하면 평균 분해를 이용하여 다음과 같이 쓸 수 있다.\n\\[\n\\begin{aligned}\n\\sum_{i=1}^{n_1}  (\\pmb X_i - \\pmb \\mu_1) (\\pmb X_i - \\pmb \\mu_1)^t\n  &=\n  \\sum_{i=1}^{n_1}  \\Big [ (\\pmb X_i - \\bar{\\pmb X}_1) + (\\bar{\\pmb X}_1 - \\pmb \\mu_1) \\Big ] \\Big [ (\\pmb X_i - \\bar{\\pmb X}_1) + (\\bar{\\pmb X}_1 - \\pmb \\mu_1) \\Big ]^t \\\\\n  &=\n  \\sum_{i=1}^{n_1}  (\\pmb X_i - \\bar{\\pmb X}_1) (\\pmb X_i - \\bar{\\pmb X}_1)^t + n_1 (\\bar{\\pmb X}_1 - \\pmb \\mu_1) (\\bar{\\pmb X}_1 - \\pmb \\mu_1)^t \\\\\n  &=\n  n_1 S_x + n_1 (\\bar{\\pmb X} - \\pmb \\mu_1) (\\bar{\\pmb X} - \\pmb \\mu_1)^t\n\\end{aligned}\n  \\tag{B.6}\\]\n위의 식에서 \\(S_x\\) 는 확률 표본 \\(\\pmb X_1, \\pmb X_2, \\dots, \\pmb X_{n_1}\\) 으로 만들어진 표본 공분산 행렬이다 (아래 식에서 공분산행렬의 추정에서 분포를 최대가능도 추정량으로 하여 \\(n_1-1\\) 대신 \\(n_1\\) 을 적용하였다)\n\\[\nS_X = \\frac{1}{n_1} \\sum_{i=1}^{n_1}  (\\pmb X_i - \\bar{\\pmb X}_1) (\\pmb X_i - \\bar{\\pmb X}_1)^t\n\\]\n이제 식 B.6 을 식 B.5 에 적용하면 다음과 같이 쓸 수 있다.\n\\[\n\\begin{aligned}\n\\sum_{i=1}^{n_1} (\\pmb X_i - \\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1)\n  &=\n\\operatorname{tr} \\Bigg [ \\pmb \\Sigma^{-1}  \\sum_{i=1}^{n_1}  (\\pmb X_i - \\pmb \\mu_1) (\\pmb X_i - \\pmb \\mu_1)^t  \\Bigg  ]  \\\\\n   &=\n  \\operatorname{tr} \\Bigg [ n_1\\pmb \\Sigma^{-1} S_x + n_1 \\pmb \\Sigma^{-1}  (\\bar{\\pmb X} - \\pmb \\mu_1) (\\bar{\\pmb X} - \\pmb \\mu_1)^t \\Bigg ] \\\\\n   &=\n  n_1  \\Bigg [ \\operatorname{tr} ( \\pmb \\Sigma^{-1} S_x ) + \\operatorname{tr} ( \\pmb \\Sigma^{-1}  (\\bar{\\pmb X} - \\pmb \\mu_1) (\\bar{\\pmb X} - \\pmb \\mu_1)^t ) \\Bigg ]  \\\\\n   &= n_1   \\operatorname{tr} ( \\pmb \\Sigma^{-1} S_x ) + n_1  (\\bar{\\pmb X} - \\pmb \\mu_1)^t \\pmb   \\Sigma^{-1}  (\\bar{\\pmb X} - \\pmb \\mu_1)\n\\end{aligned}\n\\tag{B.7}\\]\n\n\nB.2.3 로그 가능도 함수의 재표현\n이제 분해식 식 B.7 를 식 B.3 에 적용하여 제약조건이 없는 경우의 로그 가능도 함수를 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\ell({\\pmb \\mu_1},{\\pmb \\mu_2},{\\pmb \\Sigma})\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi \\pmb \\Sigma| \\\\\n& ~~ -\\frac{1}{2} \\Bigg [ \\sum_{i=1}^{n_1} (\\pmb X_i - \\pmb \\mu_1)^t \\pmb \\Sigma^{-1} (\\pmb X_i - \\pmb \\mu_1) + \\sum_{i=1}^{n_2} (\\pmb Y_i - \\pmb \\mu_2)^t \\pmb \\Sigma^{-1} (\\pmb Y_i - \\pmb \\mu_2) \\Bigg ] \\\\\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi \\pmb \\Sigma| \\\\\n& ~~ -\\frac{1}{2} \\Bigg [ n_1   \\operatorname{tr} ( \\pmb \\Sigma^{-1} S_x ) + n_1  (\\bar{\\pmb X} - \\pmb \\mu_1)^t \\pmb   \\Sigma^{-1}  (\\bar{\\pmb X} - \\pmb \\mu_1)  \\\\\n& \\quad  \\quad  \\quad + n_2   \\operatorname{tr} ( \\pmb \\Sigma^{-1} S_y ) + n_2  (\\bar{\\pmb Y} - \\pmb \\mu_2)^t \\pmb   \\Sigma^{-1}  (\\bar{\\pmb Y} - \\pmb \\mu_2)  \\Bigg ] \\\\\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} [n_1 S_x  + n_2 S_y]) \\\\\n& \\quad -\\frac{1}{2}  \\left [ n_1  (\\bar{\\pmb X} - {\\pmb \\mu_1})^t    {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb X} - {\\pmb \\mu_1})  + n_2  (\\bar{\\pmb Y} - { \\pmb \\mu_2} )^t   {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb Y} - { \\pmb \\mu_2} )  \\right ]  \\\\\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} \\pmb W ) \\\\\n& \\quad -\\frac{1}{2}  \\left [ n_1  (\\bar{\\pmb X} - {\\pmb \\mu_1})^t    {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb X} - {\\pmb \\mu_1})  + n_2  (\\bar{\\pmb Y} - { \\pmb \\mu_2} )^t   {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb Y} - { \\pmb \\mu_2} )  \\right ]\n\\end{aligned}\n\\tag{B.8}\\]\n위의 식에서 \\(\\pmb W\\) 는 그룹내의 변동을 표시하는 제곱합 행렬이다. 참고로 식 3.4 에서 정의된 풀링된 공분산 행렬 \\(\\pmb S_p\\) 와 다음과 같은 관계가 있다.\n\\[\n\\begin{aligned}\n\\pmb W & =  n_1 S_X + n_2 S_Y \\\\\n& = \\sum_{i=1}^{n_1}  (\\pmb X_i - \\bar{\\pmb X}_1) (\\pmb X_i - \\bar{\\pmb X}_1)^t + \\sum_{i=1}^{n_2}  (\\pmb Y_i - \\bar{\\pmb Y}_2) (\\pmb Y_i - \\bar{\\pmb Y}_2)^t \\\\\n& = (n_1+n_2 -2) \\pmb S_{p}\n\\end{aligned}\n\\tag{B.9}\\]\n제약조건이 없는 가능도 함수 식 B.8 에 대해서 최대 가능도 추정을 적용하면 다음과 같은 평균에 대한 최대가능도 추정량은 각각 그룹의 표본 평균이 된다.\n\\[\n\\hat{\\pmb \\mu}_1 = \\bar{\\pmb X}_1, \\quad \\hat{\\pmb \\mu}_2 = \\bar{\\pmb Y}_1\n\\]\n이제 위의 평균에 대한 최대가능도 추정량을 제약 조건이 없는 가능도 함수 식 B.8 에 대입하면 다음과 같은 식을 얻게 된다.\n\\[\n\\begin{aligned}\n\\ell(\\hat {\\pmb \\mu_1},\\hat {\\pmb \\mu_2},{\\pmb \\Sigma})\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} \\pmb W ) \\\\\n& \\quad -\\frac{1}{2}  \\left [ n_1  (\\bar{\\pmb X} - \\hat {\\pmb \\mu_1})^t   \\hat {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb X} - \\hat  {\\pmb \\mu_1})  + n_2  (\\bar{\\pmb Y} - \\hat  { \\pmb \\mu_2} )^t  \\hat {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb Y} - \\hat  { \\pmb \\mu_2} )  \\right ] \\\\\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} \\pmb W )  + 0\n\\end{aligned}\n\\]\n위의 식에서 공분산 행렬에 대한 최대가능도 추정량을 구하면 다음과 같은 추정량을 얻게되며\n\\[\n\\hat {\\pmb \\Sigma} = \\frac{1}{n_1 + n_2} \\pmb W\n\\]\n따라서 공분산 행렬에 대한 추정량을 제약조건이 없는 로그 가능도 함수에 대입하면 다음의 값을 얻게된다.\n\\[\n\\begin{aligned}\n\\ell(\\hat {\\pmb \\mu_1},\\hat {\\pmb \\mu_2},\\hat {\\pmb \\Sigma})\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi \\hat {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  \\hat {\\pmb \\Sigma}^{-1} \\pmb W ) \\\\\n& = -\\frac{n_1 + n_2 }{2}\\log|2\\pi \\hat {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  (n_1 + n_2) \\pmb W^{-1} \\pmb W ) \\\\\n& = -\\frac{n_1 + n_2 }{2}\\log|2\\pi \\hat {\\pmb \\Sigma} | -\\frac{p(n_1 + n_2)}{2}\n\\end{aligned}\n\\tag{B.10}\\]\n이제 제약조건 \\(\\pmb \\mu_1 = \\pmb \\mu_2 = \\pmb \\mu\\) 가 있는 경우의 로그 가능도 함수를 고려하자. 식 B.8 의 마지막 항을 이용하면 다음과 같이 제약 조건이 있는 가능도 함수 식 B.4 를 다음과 같이 표현할 수 있다.\n\\[\n\\begin{aligned}\n\\ell({\\pmb \\mu},{\\pmb \\Sigma})\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} \\pmb W ) \\\\\n& \\quad -\\frac{1}{2}  \\left [ n_1  (\\bar{\\pmb X} - {\\pmb \\mu})^t    {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb X} - {\\pmb \\mu})  + n_2  (\\bar{\\pmb Y} - { \\pmb \\mu} )^t   {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb Y} - { \\pmb \\mu} )  \\right ]\n\\end{aligned}\n\\tag{B.11}\\]\n위의 제약조건이 있는 로그 가능도 함수에 대하여 평균 벡터 \\(\\pmb \\mu\\) 에 최대 가능도 추정량을 구하면 다음과 같다.\n\\[ \\hat{\\pmb \\mu} = \\frac{n_1 \\bar{\\pmb X} + n_2 \\bar{\\pmb Y}}{n_1 + n_2}  \\]\n여기서 그룹 간의 변동을 나타내는 제곱합 행렬 \\(\\pmb B\\) 는 다음과 같이 정의한다.\n\\[\n\\pmb B \\equiv n_1 (\\bar{\\pmb X} - \\hat{\\pmb \\mu}) (\\bar{\\pmb X} - \\hat{\\pmb \\mu})^t + n_2 (\\bar{\\pmb Y} - \\hat{\\pmb \\mu}) (\\bar{\\pmb Y} - \\hat{\\pmb \\mu})^t\n\\tag{B.12}\\]\n이제 평균 벡터의 추정량 \\(\\hat{\\pmb \\mu}\\) 를 식 B.11 을 에 대입하면 다음과 같이 로그 가능도 함수가 나타나며\n\\[\n\\begin{aligned}\n\\ell( \\hat {\\pmb \\mu},{\\pmb \\Sigma})\n& =\n-\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} \\pmb W ) \\\\\n& \\quad -\\frac{1}{2}  \\left [ n_1  (\\bar{\\pmb X} - \\hat{\\pmb \\mu})^t    {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb X} - \\hat {\\pmb \\mu})  + n_2  (\\bar{\\pmb Y} - \\hat { \\pmb \\mu} )^t   {\\pmb \\Sigma}^{-1}  (\\bar{\\pmb Y} - \\hat { \\pmb \\mu} )  \\right ] \\\\\n& = -\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} \\pmb W ) \\\\\n& \\quad -\\frac{1}{2} \\operatorname{tr}   \\left [ {\\pmb \\Sigma}^{-1} \\{ n_1 (\\bar{\\pmb X} - \\hat{\\pmb \\mu}) (\\bar{\\pmb X} - \\hat{\\pmb \\mu})^t + n_2 (\\bar{\\pmb Y} - \\hat{\\pmb \\mu}) (\\bar{\\pmb Y} - \\hat{\\pmb \\mu})^t \\}  \\right ] \\\\\n& = -\\frac{n_1 + n_2 }{2}\\log|2\\pi {\\pmb \\Sigma} | -\\frac{1}{2} \\operatorname{tr} (  {\\pmb \\Sigma}^{-1} (\\pmb W + \\pmb B) )\n\\end{aligned}\n\\tag{B.13}\\]\n이제 오그 가능도 함수 식 B.13 에서 공분산 행렬 \\(\\pmb \\Sigma\\) 에 대한 최대 가능도 추정량을 구하면 다음과 같다.\n\\[ \\hat {\\pmb \\Sigma}_0 = \\frac{1}{n_1 + n_2} (\\pmb W + \\pmb B) \\]\n위의 공분산 행렬에 대한 추정량을 식 B.13 에 대입하면 제약조건이 있는 경우 로그 가능도 함수의 최대값은 다음과 같이 얻어진다.\n\\[\n\\ell( \\hat {\\pmb \\mu},\\hat {\\pmb \\Sigma}_0)\n= -\\frac{n_1 + n_2 }{2}\\log|2\\pi \\hat {\\pmb \\Sigma}_0 | -\\frac{p(n_1 + n_2)}{2}\n\\tag{B.14}\\]\n\n\nB.2.4 가능도비 검정 통계량\n이제 로그가능도비 통계량 \\(\\lambda\\) 를 식 B.2 에 정의된 식을 이용하여 다음과 같이 쓸 수 있다.\n\\[\n\\begin{aligned}\n\\lambda\n&= -2 \\log \\Lambda \\\\\n&= -2 \\left\\{ \\ell\\!\\left(\\hat{\\boldsymbol{\\mu}},\\,\\hat{\\boldsymbol{\\Sigma}}_{0}\\right)\n            - \\ell\\!\\left(\\hat{\\boldsymbol{\\mu}}_{1},\\,\\hat{\\boldsymbol{\\mu}}_{2},\\,\\hat{\\boldsymbol{\\Sigma}}\\right) \\right\\} \\\\\n&= N \\log \\left|\\hat{\\boldsymbol{\\Sigma}}_{0}\\right|\n  - N \\log \\left|\\hat{\\boldsymbol{\\Sigma}}\\right| \\\\\n&= N \\log \\left(\n      \\frac{ \\left|\\hat{\\boldsymbol{\\Sigma}}_{0}\\right| }{ \\left|\\hat{\\boldsymbol{\\Sigma}}\\right| }\n    \\right) \\\\\n&= N \\log \\left(\n      \\frac{ \\left|\\boldsymbol{W}+\\boldsymbol{B}\\right| }{ \\left|\\boldsymbol{W}\\right| }\n    \\right),\n\\end{aligned}\n\\tag{B.15}\\]\n위의 식에서 \\(N = n_1 + n_2\\) 이다.\n마지막으로 두 집단에서는 다음과 같은 행렬식 공식를 이용하자 (부록의 섹션 A.9 참조)\n\\[\n|{\\pmb A}+{\\pmb u} {\\pmb v}^t |=| {\\pmb A}| \\big ( {\\pmb 1} +{\\pmb v}^t {\\pmb A}^{-1} {\\pmb u} \\big )\n\\tag{B.16}\\]\n위의 정리를 이용하기 위하여 식 B.12 정의된 그룹간 제곱합 행렬 \\(\\pmb B\\) 를 다음과 같이 표현해 보자\n\\[\n\\begin{aligned}\n\\pmb B & =  n_1 (\\bar{\\pmb X} - \\hat{\\pmb \\mu}) (\\bar{\\pmb X} - \\hat{\\pmb \\mu})^t + n_2 (\\bar{\\pmb Y} - \\hat{\\pmb \\mu}) (\\bar{\\pmb Y} - \\hat{\\pmb \\mu})^t \\\\\n& = n_1 \\left [ \\bar{\\pmb X} - \\frac{n_1 \\bar{\\pmb X} + n_2 \\bar{\\pmb Y}}{N} \\right ] + n_2 \\left [ \\bar{\\pmb Y} - \\frac{n_1 \\bar{\\pmb X} + n_2 \\bar{\\pmb Y}}{N} \\right ]^t \\\\\n& = \\frac{n_1 n_2}{N} (\\bar{\\pmb X} - \\bar{\\pmb Y}) (\\bar{\\pmb X} - \\bar{\\pmb Y})^t \\\\\n& = \\alpha {\\pmb d} {\\pmb d}^t,\n\\end{aligned}\n\\tag{B.17}\\]\n위의 식에서\n\\[\n\\alpha = \\frac{n_1 n_2}{N}, \\quad d = \\bar{\\pmb X} - \\bar{\\pmb Y}\n\\]\n따라서 식 B.16 에서 \\(\\pmb u = \\pmb v = \\sqrt{\\alpha} \\pmb d\\) 로 놓으면\n\\[\n\\begin{aligned}\n| {\\pmb W} + {\\pmb B} | & = | {\\pmb W} + \\alpha {\\pmb d} {\\pmb d}^t | \\\\\n&= |{\\pmb W}|  \\left( {\\pmb 1} + \\alpha {\\pmb d}^t {\\pmb W}^{-1} {\\pmb d} \\right)\n\\end{aligned}\n\\] 이제 위의 식을 식 B.15 에 넣고 정리하면 다음과 같은 결과를 얻는다.\n\\[\n\\begin{aligned}\n\\lambda\n&= -2 \\log \\Lambda \\\\\n&= N \\log \\left(\n      \\frac{ \\left|\\boldsymbol{W}+\\boldsymbol{B}\\right| }{ \\left|\\boldsymbol{W}\\right| }\n    \\right) \\\\\n&= N \\log \\left(\n      \\frac{ |{\\pmb W}|  \\left( 1 + \\alpha {\\pmb d}^t {\\pmb W}^{-1} {\\pmb d} \\right) }{ |{\\pmb W}| }\n    \\right) \\\\\n&= N \\log\\Big(1+\\alpha\\ d^\\top W^{-1} d\\Big) \\\\\n& = N \\log \\Big ( 1+ \\frac{T^2}{N-2} \\Big )\n\\end{aligned}\n\\tag{B.18}\\]\n위의 식에서 주어진 \\(T^2\\) 는 식 3.5 에서 장의한 Hotelling의 \\(T^2\\) 통계량이다. 따라서 로그 가능도비 검정 통계량 \\(\\lambda\\) 와 Hotelling의 \\(T^2\\) 통계량은 단조 증가 함수 관계에 있음을 알 수 있다. 이러한 결과로서 Hotelling의 \\(T^2\\) 을 이용한 검정은 가능도비 검정이다.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>가능도비 검정</span>"
    ]
  }
]